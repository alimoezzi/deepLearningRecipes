{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN image classification in Pytorch using CIFAR-10 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torchsummary import summary\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Normalize the test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = CIFAR10('.pytorch/CIGAR10', train=True, transform=transform_train, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10('.pytorch/CIGAR10', train=False, transform=transform_test, download=True)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "              SELU-3           [-1, 32, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          18,496\n",
      "              SELU-5           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
      "              SELU-9          [-1, 128, 16, 16]               0\n",
      "           Conv2d-10          [-1, 128, 16, 16]         147,584\n",
      "             SELU-11          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-12            [-1, 128, 8, 8]               0\n",
      "        Dropout2d-13            [-1, 128, 8, 8]               0\n",
      "           Conv2d-14            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-15            [-1, 256, 8, 8]             512\n",
      "             SELU-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17            [-1, 256, 8, 8]         590,080\n",
      "             SELU-18            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-19            [-1, 256, 4, 4]               0\n",
      "          Dropout-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 1024]       4,195,328\n",
      "             SELU-22                 [-1, 1024]               0\n",
      "           Linear-23                  [-1, 512]         524,800\n",
      "             SELU-24                  [-1, 512]               0\n",
      "          Dropout-25                  [-1, 512]               0\n",
      "           Linear-26                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 5,852,170\n",
      "Trainable params: 5,852,170\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.96\n",
      "Params size (MB): 22.32\n",
      "Estimated Total Size (MB): 26.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"CNN\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(4096, 1024),\n",
    "        nn.SELU(inplace=True),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.SELU(inplace=True),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x ):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x.view(x.size(0),-1))\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "summary(model, input_size=iter(trainloader).next()[0][0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "if os.path.isdir('checkpoint'):\n",
    "    model.load_state_dict(torch.load('./checkpoint/ckpt.t7'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-bf5efff90441>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m16\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    219\u001B[0m                 \u001B[0mretain_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m                 create_graph=create_graph)\n\u001B[1;32m--> 221\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    222\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m    130\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    131\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 132\u001B[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    133\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    134\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.05, weight_decay=0.001)\n",
    "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
    "\n",
    "for epoch in range(30):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for _, (inputs, labels) in enumerate(trainloader, 1):\n",
    "        # get the inputs\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        if epoch > 16:\n",
    "            for group in optimizer.param_groups:\n",
    "                for p in group['params']:\n",
    "                    state = optimizer.state[p]\n",
    "                    if state['step'] >= 1024:\n",
    "                        state['step'] = 1000\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Normalizing the loss by the total number of train batches\n",
    "    running_loss /= len(trainloader)\n",
    "\n",
    "    # Calculate training/test set accuracy of the existing model\n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    for _, (images, labels) in enumerate(testloader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logps = model(images)\n",
    "        batch_loss = criterion(logps, labels)\n",
    "        test_loss += batch_loss.item()\n",
    "\n",
    "        output = logps\n",
    "        pred = torch.argmax(output, 1)\n",
    "        total += labels.size(0)\n",
    "        num_correct += (pred == labels).sum().item()\n",
    "\n",
    "    test_tracker.append(test_loss/len(testloader))\n",
    "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
    "    accuracy_tracker.append(num_correct/total)\n",
    "    print(f'Accuracy : {num_correct/total}')\n",
    "\n",
    "    print(\"Iteration: {0} | Loss: {1} | Test accuracy: {2}%\".format(epoch+1, running_loss,  num_correct * 100 / total))\n",
    "\n",
    "    # save model\n",
    "    if epoch % 3 == 0:\n",
    "        print('==> Saving model ...')\n",
    "\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(model.state_dict(), './checkpoint/ckpt.t7')\n",
    "\n",
    "print('==> Finished Training ...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}