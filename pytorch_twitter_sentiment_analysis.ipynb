{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_twitter_sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "oYCfnhWzJrUI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Twitter Sentiment Analysis Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS1rkSnEJrUQ",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "cdbd5e4c-9d32-42f0-e8e4-c397f5b77100"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import imblearn\n",
        "import torch\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "from gensim.utils import tokenize\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "from torchtext.legacy import data\n",
        "# from torchtext import data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show, output_file\n",
        "from collections import Counter\n",
        "from functools import reduce\n",
        "! pip install captum bokeh spacy emot\n",
        "import captum\n",
        "import spacy\n",
        "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, IntegratedGradients, LayerConductance\n",
        "from captum.attr import visualization as viz\n",
        "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
        "import emot\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "! python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load('en')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: emot in /usr/local/lib/python3.7/dist-packages (2.1)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum) (1.8.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh) (2.8.1)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh) (20.9)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh) (5.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh) (3.7.4.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.2.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DETgMPgJrUS",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "QwFJPG55JrUT",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "9d8b44f8-f467-484f-c72c-d50e5072e2dc"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/dipikabaad/Sentiment_Classification_with_RNN/master/Tweets.csv --create-dirs -o .pytorch/tweets/tweets.csv\n",
        "!mkdir checkpoint\n",
        "df = pd.read_csv('.pytorch/tweets/tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3341k  100 3341k    0     0  9827k      0 --:--:-- --:--:-- --:--:-- 9827k\n",
            "mkdir: cannot create directory ‘checkpoint’: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnZDU5kUJrUT"
      },
      "source": [
        "### Exploring features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "8iEEuqAuJrUT",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "2ba79036-b670-4547-90dd-e12bc2c63875"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>retweet_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.464000e+04</td>\n",
              "      <td>14640.000000</td>\n",
              "      <td>10522.000000</td>\n",
              "      <td>14640.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.692184e+17</td>\n",
              "      <td>0.900169</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.082650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.791112e+14</td>\n",
              "      <td>0.162830</td>\n",
              "      <td>0.330440</td>\n",
              "      <td>0.745778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.675883e+17</td>\n",
              "      <td>0.335000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.685592e+17</td>\n",
              "      <td>0.692300</td>\n",
              "      <td>0.360600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.694779e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.670600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.698905e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.703106e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           tweet_id  ...  retweet_count\n",
              "count  1.464000e+04  ...   14640.000000\n",
              "mean   5.692184e+17  ...       0.082650\n",
              "std    7.791112e+14  ...       0.745778\n",
              "min    5.675883e+17  ...       0.000000\n",
              "25%    5.685592e+17  ...       0.000000\n",
              "50%    5.694779e+17  ...       0.000000\n",
              "75%    5.698905e+17  ...       0.000000\n",
              "max    5.703106e+17  ...      44.000000\n",
              "\n",
              "[8 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLQm2ZkvJrUU",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "HLQhe0zgJrUU",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "0f9aab2b-3fa1-44ff-8df1-986582b55864"
      },
      "source": [
        "df.groupby('airline_sentiment').describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">tweet_id</th>\n",
              "      <th colspan=\"8\" halign=\"left\">airline_sentiment_confidence</th>\n",
              "      <th colspan=\"8\" halign=\"left\">negativereason_confidence</th>\n",
              "      <th colspan=\"8\" halign=\"left\">retweet_count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>9178.0</td>\n",
              "      <td>5.692602e+17</td>\n",
              "      <td>7.572474e+14</td>\n",
              "      <td>5.675900e+17</td>\n",
              "      <td>5.686511e+17</td>\n",
              "      <td>5.695355e+17</td>\n",
              "      <td>5.698798e+17</td>\n",
              "      <td>5.703106e+17</td>\n",
              "      <td>9178.0</td>\n",
              "      <td>0.933365</td>\n",
              "      <td>0.138109</td>\n",
              "      <td>0.3394</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9178.0</td>\n",
              "      <td>0.731769</td>\n",
              "      <td>0.238276</td>\n",
              "      <td>0.3122</td>\n",
              "      <td>0.6453</td>\n",
              "      <td>0.6806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9178.0</td>\n",
              "      <td>0.093375</td>\n",
              "      <td>0.792865</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>3099.0</td>\n",
              "      <td>5.691841e+17</td>\n",
              "      <td>8.068405e+14</td>\n",
              "      <td>5.675883e+17</td>\n",
              "      <td>5.684852e+17</td>\n",
              "      <td>5.693080e+17</td>\n",
              "      <td>5.699305e+17</td>\n",
              "      <td>5.703093e+17</td>\n",
              "      <td>3099.0</td>\n",
              "      <td>0.823303</td>\n",
              "      <td>0.185594</td>\n",
              "      <td>0.3350</td>\n",
              "      <td>0.66605</td>\n",
              "      <td>0.916</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3099.0</td>\n",
              "      <td>0.060987</td>\n",
              "      <td>0.658037</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>2363.0</td>\n",
              "      <td>5.691006e+17</td>\n",
              "      <td>8.112476e+14</td>\n",
              "      <td>5.676555e+17</td>\n",
              "      <td>5.684331e+17</td>\n",
              "      <td>5.691980e+17</td>\n",
              "      <td>5.698788e+17</td>\n",
              "      <td>5.703093e+17</td>\n",
              "      <td>2363.0</td>\n",
              "      <td>0.872039</td>\n",
              "      <td>0.179478</td>\n",
              "      <td>0.3356</td>\n",
              "      <td>0.67750</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2363.0</td>\n",
              "      <td>0.069403</td>\n",
              "      <td>0.659914</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  tweet_id                              ... retweet_count           \n",
              "                     count          mean           std  ...           50%  75%   max\n",
              "airline_sentiment                                       ...                         \n",
              "negative            9178.0  5.692602e+17  7.572474e+14  ...           0.0  0.0  44.0\n",
              "neutral             3099.0  5.691841e+17  8.068405e+14  ...           0.0  0.0  28.0\n",
              "positive            2363.0  5.691006e+17  8.112476e+14  ...           0.0  0.0  22.0\n",
              "\n",
              "[3 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgpw8FCZJrUV",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "4f3f2daf-ae91-48e9-fffd-642d6ceb8c47"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14640 entries, 0 to 14639\n",
            "Data columns (total 15 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   tweet_id                      14640 non-null  int64  \n",
            " 1   airline_sentiment             14640 non-null  object \n",
            " 2   airline_sentiment_confidence  14640 non-null  float64\n",
            " 3   negativereason                9178 non-null   object \n",
            " 4   negativereason_confidence     10522 non-null  float64\n",
            " 5   airline                       14640 non-null  object \n",
            " 6   airline_sentiment_gold        40 non-null     object \n",
            " 7   name                          14640 non-null  object \n",
            " 8   negativereason_gold           32 non-null     object \n",
            " 9   retweet_count                 14640 non-null  int64  \n",
            " 10  text                          14640 non-null  object \n",
            " 11  tweet_coord                   1019 non-null   object \n",
            " 12  tweet_created                 14640 non-null  object \n",
            " 13  tweet_location                9907 non-null   object \n",
            " 14  user_timezone                 9820 non-null   object \n",
            "dtypes: float64(2), int64(2), object(11)\n",
            "memory usage: 1.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oGU6704JrUV",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "4e722407-3c6d-47de-8cb3-708662868096"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id                            0\n",
              "airline_sentiment                   0\n",
              "airline_sentiment_confidence        0\n",
              "negativereason                   5462\n",
              "negativereason_confidence        4118\n",
              "airline                             0\n",
              "airline_sentiment_gold          14600\n",
              "name                                0\n",
              "negativereason_gold             14608\n",
              "retweet_count                       0\n",
              "text                                0\n",
              "tweet_coord                     13621\n",
              "tweet_created                       0\n",
              "tweet_location                   4733\n",
              "user_timezone                    4820\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "QFUejj4jJrUV",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "12dcc85b-cfa3-4c0d-ca2f-2d40251f773b"
      },
      "source": [
        "df[df['text'].str.len() < 2]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [tweet_id, airline_sentiment, airline_sentiment_confidence, negativereason, negativereason_confidence, airline, airline_sentiment_gold, name, negativereason_gold, retweet_count, text, tweet_coord, tweet_created, tweet_location, user_timezone]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "yZ6t1ICXJrUW",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "63d0c017-6780-4b79-aed9-e20dd8ee25a3"
      },
      "source": [
        "df[df.duplicated('text')]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>568605449659895808</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.6482</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SuuperG</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica Thanks!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-19 18:57:58 -0800</td>\n",
              "      <td>Wandering So-Cal-ian</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>570299889688702976</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.6634</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nydia376</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@united thanks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:11:04 -0800</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>569705563287896064</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tiamariaroxs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@united thank you!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 19:49:25 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864</th>\n",
              "      <td>569545805826166784</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3512</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>United</td>\n",
              "      <td>NaN</td>\n",
              "      <td>worldknits</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@united thank you</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 09:14:36 -0800</td>\n",
              "      <td>Fredericksburg, VA</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>569513703722393601</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Angry_VBK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@united thank you</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 07:07:02 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13995</th>\n",
              "      <td>569680231012773888</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Customer Service Issue</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LBernieMeyer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@AmericanAir  800 number will not even let you...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 18:08:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14386</th>\n",
              "      <td>569622568459636736</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Customer Service Issue</td>\n",
              "      <td>0.6398</td>\n",
              "      <td>American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SchrierCar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@AmericanAir I want to speak to a human being!...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 14:19:38 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14392</th>\n",
              "      <td>569621879633391616</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Customer Service Issue</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>salitron78</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@AmericanAir no response to DM or email yet.  ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 14:16:53 -0800</td>\n",
              "      <td>on @TheJR</td>\n",
              "      <td>Seoul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14543</th>\n",
              "      <td>569601363799359488</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Flight Attendant Complaints</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>stevereasnors</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@AmericanAir should reconsider #usairways acqu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 12:55:22 -0800</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14556</th>\n",
              "      <td>569600137296633856</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>douglaskgordon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@AmericanAir Thank you.....you do the same!!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-22 12:50:30 -0800</td>\n",
              "      <td>Caribbean, New York and Miami.</td>\n",
              "      <td>Indiana (East)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>213 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...               user_timezone\n",
              "331    568605449659895808  ...  Pacific Time (US & Canada)\n",
              "515    570299889688702976  ...                         NaN\n",
              "1477   569705563287896064  ...                         NaN\n",
              "1864   569545805826166784  ...  Eastern Time (US & Canada)\n",
              "1938   569513703722393601  ...                         NaN\n",
              "...                   ...  ...                         ...\n",
              "13995  569680231012773888  ...                         NaN\n",
              "14386  569622568459636736  ...                         NaN\n",
              "14392  569621879633391616  ...                       Seoul\n",
              "14543  569601363799359488  ...  Pacific Time (US & Canada)\n",
              "14556  569600137296633856  ...              Indiana (East)\n",
              "\n",
              "[213 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "HHfQVsljJrUW",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "6f4c7d6e-3ced-4f97-b63b-20d0c97a1c1c"
      },
      "source": [
        "df.drop_duplicates('text', inplace=True)\n",
        "df[df.duplicated('text')]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [tweet_id, airline_sentiment, airline_sentiment_confidence, negativereason, negativereason_confidence, airline, airline_sentiment_gold, name, negativereason_gold, retweet_count, text, tweet_coord, tweet_created, tweet_location, user_timezone]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "y_GcsS8iJrUX",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "9d7dd307-2055-4be0-c01e-9a63b37d2433"
      },
      "source": [
        "df[['airline_sentiment', 'text']].groupby('airline_sentiment').count().plot.bar()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4419eeb5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRNRGUr1JrUX"
      },
      "source": [
        "### Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Sbn3-qJrUX"
      },
      "source": [
        "#### Steps\n",
        "1. One-hot encode output\n",
        "2. Replace tags and metion with a unique symbol\n",
        "3. Replace `emoji` and `emoticons` with their meaning\n",
        "4. Remove stop-words\n",
        "5. Remove punctuation and tokenize sentences\n",
        "6. Stemming each token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iy0yXqzYJrUY",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "d385cb7c-9d1c-4541-acab-89198582bc7e"
      },
      "source": [
        "\n",
        "condlist = [\n",
        "    df['airline_sentiment'].str.match('neutral'),\n",
        "    df['airline_sentiment'].str.match('positive'),\n",
        "    df['airline_sentiment'].str.match('negative')\n",
        "]\n",
        "df['sentiment'] = np.select(condlist, [0,1,2])\n",
        "d = df[['text', 'sentiment']]\n",
        "d.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0                @VirginAmerica What @dhepburn said.          0\n",
              "1  @VirginAmerica plus you've added commercials t...          1\n",
              "2  @VirginAmerica I didn't today... Must mean I n...          0\n",
              "3  @VirginAmerica it's really aggressive to blast...          2\n",
              "4  @VirginAmerica and it's a really big bad thing...          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xHC-GTGIJrUY",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "06bcb3ff-7a72-4dae-ee92-78f0ec643909"
      },
      "source": [
        "def emoji_helper(text):\n",
        "    clean_mean = lambda x:  x.replace('-', '_').replace(':', ' ')\n",
        "    for emoti in emot.emo_unicode.EMOTICONS:\n",
        "        if emoti in text:\n",
        "            text = text.replace(emoti, clean_mean(emot.emo_unicode.EMOTICONS.get(emoti, '')))\n",
        "\n",
        "    for emoti in emot.emo_unicode.UNICODE_EMO:\n",
        "        if emoti in text:\n",
        "            text = text.replace(emoti, clean_mean(emot.emo_unicode.UNICODE_EMO.get(emoti, '')))\n",
        "\n",
        "    for emoti in emot.emo_unicode.EMOTICONS_EMO:\n",
        "        if emoti in text:\n",
        "            text = text.replace(emoti, clean_mean(emot.emo_unicode.EMOTICONS_EMO.get(emoti, '')).replace(' ','_'))\n",
        "    return text\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    return [porter_stemmer.stem(word) for word in\n",
        "        simple_preprocess(remove_stopwords(emoji_helper(re.sub(r'\\s*([@#][\\w_-]+)', '', str(x)))), deacc=True)\n",
        "    ]\n",
        "\n",
        "d['text'] = d['text'].apply(func=lambda x:preprocess(x))\n",
        "\n",
        "d"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[what, said]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[plu, you, ve, ad, commerci, experi, tacki]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[didn, todai, must, mean, need, trip]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[it, aggress, blast, obnoxi, entertain, guest,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[it, big, bad, thing]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14635</th>\n",
              "      <td>[thank, got, differ, flight, chicago]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14636</th>\n",
              "      <td>[leav, minut, late, flight, no, warn, commun, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14637</th>\n",
              "      <td>[pleas, bring, american, airlin]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14638</th>\n",
              "      <td>[monei, chang, flight, don, answer, phone, ani...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14639</th>\n",
              "      <td>[ppl, need, know, seat, flight, plz, standbi, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14427 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  sentiment\n",
              "0                                           [what, said]          0\n",
              "1            [plu, you, ve, ad, commerci, experi, tacki]          1\n",
              "2                  [didn, todai, must, mean, need, trip]          0\n",
              "3      [it, aggress, blast, obnoxi, entertain, guest,...          2\n",
              "4                                  [it, big, bad, thing]          2\n",
              "...                                                  ...        ...\n",
              "14635              [thank, got, differ, flight, chicago]          1\n",
              "14636  [leav, minut, late, flight, no, warn, commun, ...          2\n",
              "14637                   [pleas, bring, american, airlin]          0\n",
              "14638  [monei, chang, flight, don, answer, phone, ani...          2\n",
              "14639  [ppl, need, know, seat, flight, plz, standbi, ...          0\n",
              "\n",
              "[14427 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1lsg8zVJrUY"
      },
      "source": [
        "#### Analyze review length\n",
        "Here we remove the outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE-zLQLWJrUZ",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "dc2407f2-9249-433c-b836-7dcb20cceb01"
      },
      "source": [
        "d['text'].str.len().describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    14427.000000\n",
              "mean         9.361128\n",
              "std          4.221203\n",
              "min          0.000000\n",
              "25%          6.000000\n",
              "50%         10.000000\n",
              "75%         12.000000\n",
              "max         49.000000\n",
              "Name: text, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "241NoGKyJrUZ",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "d948c451-8960-4cd4-b003-4bf33c618c33"
      },
      "source": [
        "d['text'].str.len().hist()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4419980190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YKCZ7SYYJrUZ",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "70c99c6c-39e2-4dc0-bc9d-6ea4386a4833"
      },
      "source": [
        "d = d[ (2 < d['text'].str.len()) & (d['text'].str.len() < 24) ]\n",
        "d['text'].str.len().hist()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4418e07790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FTBryPnJrUa",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Creating vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6jBsOu6JrUa",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "max_document_length = d['text'].str.len().max()  # each sentence has until 100 words\n",
        "max_size = 5000\n",
        "Text = data.Field(batch_first=True, tokenize=lambda x: x, include_lengths=True, fix_length=max_document_length)\n",
        "Label = data.Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)\n",
        "fields = [('text', Text), ('labels', Label)]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOIRUDjzJrUa",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "83ec3f9d-e997-46ca-a3f7-ff710a9a8b5d"
      },
      "source": [
        "class DataFrameDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, df, text_field, label_field, is_test=False, **kwargs):\n",
        "        fields = [('text', text_field), ('labels', label_field)]\n",
        "        examples = []\n",
        "        for i, row in df.iterrows():\n",
        "            label = row.sentiment\n",
        "            text = row.text\n",
        "            examples.append(data.Example.fromlist([text, label], fields))\n",
        "\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.text)\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, text_field, label_field, train_df, test_df=None, **kwargs):\n",
        "        train_data, test_data = (None, None)\n",
        "\n",
        "        if train_df is not None:\n",
        "            train_data = cls(train_df.copy(), text_field, label_field, **kwargs)\n",
        "        if test_df is not None:\n",
        "            test_data = cls(test_df.copy(), text_field, label_field, True, **kwargs)\n",
        "\n",
        "        return tuple(d for d in (train_data, test_data) if d is not None)\n",
        "test_size = 0.2 # split percentage to train\\validation data\n",
        "X_train,X_test,y_train,y_test = train_test_split(d['text'].index,d['sentiment'], test_size=test_size, random_state=0, stratify=d['sentiment'])\n",
        "train_df = d.loc[X_train.values]\n",
        "test_df = d.loc[X_test.values]\n",
        "train_ds, test_ds = DataFrameDataset.splits(\n",
        "    text_field=Text, label_field=Label, train_df=train_df, test_df=test_df)\n",
        "vars(test_ds[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0, 'text': ['rd', 'time', 'jamaica', 'volunt', 'risk', 'youth']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rzlLLUsKDPJ"
      },
      "source": [
        "### Checking how balance is our testset in comparison to trainset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fU_1ta2JuSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "5d18405b-0d37-4c98-8ab1-fca7c76b538a"
      },
      "source": [
        "test_df.groupby('sentiment').count()/test_df['sentiment'].count()*100"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.941241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.167095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.891664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text\n",
              "sentiment           \n",
              "0          19.941241\n",
              "1          15.167095\n",
              "2          64.891664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-8DkMpgJ8Nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1ede3cf6-6168-4fd0-edcd-ab43660b7fc8"
      },
      "source": [
        "train_df.groupby('sentiment').count()/train_df['sentiment'].count()*100"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.952254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.140942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.906804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text\n",
              "sentiment           \n",
              "0          19.952254\n",
              "1          15.140942\n",
              "2          64.906804"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SFHEes6ewWpa",
        "outputId": "af82c2c5-f1ea-44be-83af-3330eec8e190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "items = train_df.groupby('sentiment').count().to_numpy()\n",
        "neu, pos, neg = items[0][0], items[1][0], items[2][0]\n",
        "total = train_df.count()[0]\n",
        "weight_for_0 = (1 / neu)*(total)/2.0\n",
        "weight_for_1 = (1 / pos)*(total)/2.0\n",
        "weight_for_2 = (1 / neg)*(total)/1.5\n",
        "print(weight_for_0, weight_for_1, weight_for_2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5059825126553155 3.3023044269254096 1.0271136888763144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4QWhGExJrUb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "Text.build_vocab(train_ds, test_ds, max_size=max_size)\n",
        "Label.build_vocab(train_ds)\n",
        "vocab_size = len(Text.vocab)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm69dUmTJrUb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "PAD_IND = Text.vocab.stoi['pad']\n",
        "# captum\n",
        "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND) # create a reference (aka baseline) for the sentences and its constituent parts, tokens"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5xCcMgXJrUb",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjpQpWbkJrUb",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "8df6d548-7ad3-4a69-c332-94b1b29e0809"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFri3ivlJrUc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    # define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, output_dim, n_layers,\n",
        "                 bidirectional, dropout, pad_index):\n",
        "        # Constructor\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.bidirectional = bidirectional\n",
        "        # embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "\n",
        "        # lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim1,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim1 * 2, hidden_dim2)\n",
        "        self.fc2 = nn.Linear(hidden_dim2, output_dim)\n",
        "        self.relu = nn.SELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        # activation function\n",
        "        self.act = nn.Softmax() #\\ F.log_softmax(outp)\n",
        "\n",
        "    def forward(self, text, text_lengths, hid=None):\n",
        "        # text = [batch size,sent_length]\n",
        "        if hid == None:\n",
        "            hid = self.init_hidden(text.shape[0])\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "\n",
        "        # packed sequence\n",
        "        packed_embedded = pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True) # unpad\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded, hid)\n",
        "        # packed_output shape = (batch, seq_len, num_directions * hidden_size)\n",
        "        # hidden shape  = (num_layers * num_directions, batch, hidden_size)\n",
        "\n",
        "        # concat the final forward and backward hidden state\n",
        "        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        # output, output_lengths = pad_packed_sequence(packed_output)  # pad the sequence to the max length in the batch\n",
        "        cat = self.dropout1(cat)\n",
        "        rel = self.relu(cat)\n",
        "        dense1 = self.fc1(rel)\n",
        "\n",
        "        drop = self.dropout(dense1)\n",
        "        preds = self.fc2(drop)\n",
        "\n",
        "        # Final activation function\n",
        "        # preds = self.act(preds)\n",
        "        # preds = preds.argmax(dim=1).unsqueeze(0)\n",
        "        return preds, (hidden, cell)\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        hidden = (torch.zeros(self.n_layers*(2 if self.bidirectional else 1), batch_size, self.hidden_dim1).to(device),\n",
        "                  torch.zeros(self.n_layers*(2 if self.bidirectional else 1), batch_size, self.hidden_dim1).to(device))\n",
        "\n",
        "        return hidden"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zLwnk5UJrUg",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "6c557f6e-08c1-4e84-bd9a-1cd6754455af"
      },
      "source": [
        "\n",
        "# hyper-parameters:\n",
        "lr = 1e-4\n",
        "batch_size = 50\n",
        "dropout_keep_prob = 0.5\n",
        "embedding_size = 300\n",
        "seed = 0\n",
        "clip=5\n",
        "num_classes = 3\n",
        "num_hidden_nodes = 93\n",
        "hidden_dim2 = 512\n",
        "num_layers = 2  # LSTM layers\n",
        "bi_directional = True\n",
        "num_epochs = 100\n",
        "\n",
        "pad_index = Text.vocab.stoi[Text.pad_token]\n",
        "\n",
        "# Build the model\n",
        "lstm_model = LSTM(vocab_size, embedding_size, num_hidden_nodes, hidden_dim2 , num_classes, num_layers,\n",
        "                  bi_directional, dropout_keep_prob, pad_index)\n",
        "lstm_model.to(device)\n",
        "print(lstm_model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (embedding): Embedding(5002, 1024, padding_idx=1)\n",
            "  (lstm): LSTM(1024, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=3, bias=True)\n",
            "  (relu): SELU()\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            "  (dropout1): Dropout(p=0.7, inplace=False)\n",
            "  (act): Softmax(dim=None)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLmmdfsyJrUk",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tESutgn6JrUk",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits((train_ds, test_ds),\n",
        "                                                           batch_size=batch_size,\n",
        "                                                           sort_key=lambda x: len(x.text),\n",
        "                                                           # Sort the batches by text length size\n",
        "                                                           sort_within_batch=True,\n",
        "                                                           device=device,\n",
        "                                                           )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne_LiAoSJrUk",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def accuracy(probs, target):\n",
        "    winners = probs.argmax(dim=1)\n",
        "    corrects = (winners == target)\n",
        "    accuracy = corrects.sum().float() / float(target.size(0))\n",
        "    return accuracy\n",
        "\n",
        "def plot_cm(y_true, y_pred, target_names):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=target_names)\n",
        "    plt.figure(figsize=(5,5))\n",
        "    sb.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    h = model.init_hidden(batch_size)\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        # zero accumulated gradients\n",
        "        model.zero_grad()\n",
        "        # retrieve text and no. of words\n",
        "        text, text_lengths = batch.text\n",
        "        if (text.shape[0], text.shape[1]) != (batch_size, max_document_length):\n",
        "            continue\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        predictions, h = model(text, text_lengths, h)\n",
        "        loss = criterion(predictions, batch.labels.squeeze())\n",
        "\n",
        "        acc = accuracy(predictions, batch.labels)\n",
        "\n",
        "        # perform backpropagation\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, report=False):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    report_pred_test =[]\n",
        "    report_label_test =[]\n",
        "\n",
        "    model.eval()\n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "            if (text.shape[0], text.shape[1]) != (batch_size, max_document_length):\n",
        "                continue\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "            predictions, val_h = model(text, text_lengths, val_h)\n",
        "\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "\n",
        "            acc = accuracy(predictions, batch.labels)\n",
        "            if report:\n",
        "                report_pred_test.extend(predictions.argmax(dim=1).cpu())\n",
        "                report_label_test.extend(batch.labels.cpu())\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    if report:\n",
        "        print(classification_report(report_label_test, report_pred_test, target_names=['neutral', 'positive', 'negative']))\n",
        "        plot_cm(report_label_test, report_pred_test, target_names=[0, 1, 2])\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def run_train(epochs, model, train_iterator, valid_iterator, optimizer, criterion):\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # train the model\n",
        "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "        # evaluate the model\n",
        "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "        # save the best model\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'checkpoint/twitter.t7')\n",
        "\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPadIekjJrUl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss(weight=torch.tensor([weight_for_0, weight_for_1, weight_for_2], dtype=torch.float32, device=device))\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IXSVKXpkJrUl",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "66d4f20d-bc97-437a-91a1-fd6647e921a5"
      },
      "source": [
        "run_train(num_epochs, lstm_model, train_iterator, test_iterator, optimizer, loss_func)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.066 | Train Acc: 42.58%\n",
            "\t Val. Loss: 0.983 |  Val. Acc: 61.97%\n",
            "\tTrain Loss: 1.052 | Train Acc: 54.12%\n",
            "\t Val. Loss: 0.968 |  Val. Acc: 62.93%\n",
            "\tTrain Loss: 1.034 | Train Acc: 61.93%\n",
            "\t Val. Loss: 0.950 |  Val. Acc: 63.49%\n",
            "\tTrain Loss: 1.016 | Train Acc: 65.14%\n",
            "\t Val. Loss: 0.928 |  Val. Acc: 63.64%\n",
            "\tTrain Loss: 0.991 | Train Acc: 66.61%\n",
            "\t Val. Loss: 0.901 |  Val. Acc: 63.46%\n",
            "\tTrain Loss: 0.959 | Train Acc: 67.42%\n",
            "\t Val. Loss: 0.870 |  Val. Acc: 63.46%\n",
            "\tTrain Loss: 0.929 | Train Acc: 67.47%\n",
            "\t Val. Loss: 0.840 |  Val. Acc: 63.35%\n",
            "\tTrain Loss: 0.895 | Train Acc: 67.91%\n",
            "\t Val. Loss: 0.812 |  Val. Acc: 62.96%\n",
            "\tTrain Loss: 0.866 | Train Acc: 68.17%\n",
            "\t Val. Loss: 0.790 |  Val. Acc: 63.03%\n",
            "\tTrain Loss: 0.842 | Train Acc: 68.53%\n",
            "\t Val. Loss: 0.771 |  Val. Acc: 63.32%\n",
            "\tTrain Loss: 0.815 | Train Acc: 69.39%\n",
            "\t Val. Loss: 0.755 |  Val. Acc: 63.60%\n",
            "\tTrain Loss: 0.797 | Train Acc: 69.59%\n",
            "\t Val. Loss: 0.741 |  Val. Acc: 63.74%\n",
            "\tTrain Loss: 0.779 | Train Acc: 69.98%\n",
            "\t Val. Loss: 0.728 |  Val. Acc: 64.10%\n",
            "\tTrain Loss: 0.763 | Train Acc: 70.47%\n",
            "\t Val. Loss: 0.718 |  Val. Acc: 64.20%\n",
            "\tTrain Loss: 0.747 | Train Acc: 71.60%\n",
            "\t Val. Loss: 0.707 |  Val. Acc: 64.28%\n",
            "\tTrain Loss: 0.726 | Train Acc: 71.78%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 64.20%\n",
            "\tTrain Loss: 0.717 | Train Acc: 72.09%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 64.42%\n",
            "\tTrain Loss: 0.697 | Train Acc: 72.25%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 64.10%\n",
            "\tTrain Loss: 0.684 | Train Acc: 73.22%\n",
            "\t Val. Loss: 0.679 |  Val. Acc: 64.17%\n",
            "\tTrain Loss: 0.667 | Train Acc: 73.21%\n",
            "\t Val. Loss: 0.673 |  Val. Acc: 64.20%\n",
            "\tTrain Loss: 0.655 | Train Acc: 73.37%\n",
            "\t Val. Loss: 0.668 |  Val. Acc: 64.38%\n",
            "\tTrain Loss: 0.643 | Train Acc: 74.23%\n",
            "\t Val. Loss: 0.667 |  Val. Acc: 64.35%\n",
            "\tTrain Loss: 0.629 | Train Acc: 74.16%\n",
            "\t Val. Loss: 0.662 |  Val. Acc: 64.35%\n",
            "\tTrain Loss: 0.620 | Train Acc: 74.15%\n",
            "\t Val. Loss: 0.660 |  Val. Acc: 64.45%\n",
            "\tTrain Loss: 0.615 | Train Acc: 74.65%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 64.70%\n",
            "\tTrain Loss: 0.607 | Train Acc: 74.92%\n",
            "\t Val. Loss: 0.653 |  Val. Acc: 64.81%\n",
            "\tTrain Loss: 0.592 | Train Acc: 75.28%\n",
            "\t Val. Loss: 0.651 |  Val. Acc: 64.63%\n",
            "\tTrain Loss: 0.586 | Train Acc: 75.31%\n",
            "\t Val. Loss: 0.650 |  Val. Acc: 65.34%\n",
            "\tTrain Loss: 0.565 | Train Acc: 76.30%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 65.45%\n",
            "\tTrain Loss: 0.557 | Train Acc: 76.19%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 65.55%\n",
            "\tTrain Loss: 0.556 | Train Acc: 76.22%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 65.38%\n",
            "\tTrain Loss: 0.542 | Train Acc: 76.91%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 65.91%\n",
            "\tTrain Loss: 0.533 | Train Acc: 77.23%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 65.66%\n",
            "\tTrain Loss: 0.518 | Train Acc: 77.80%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 66.05%\n",
            "\tTrain Loss: 0.517 | Train Acc: 78.42%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 65.55%\n",
            "\tTrain Loss: 0.502 | Train Acc: 78.45%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 65.77%\n",
            "\tTrain Loss: 0.500 | Train Acc: 78.73%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 65.94%\n",
            "\tTrain Loss: 0.491 | Train Acc: 78.64%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 66.26%\n",
            "\tTrain Loss: 0.478 | Train Acc: 79.26%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 66.30%\n",
            "\tTrain Loss: 0.473 | Train Acc: 79.49%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 66.58%\n",
            "\tTrain Loss: 0.460 | Train Acc: 79.73%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 66.97%\n",
            "\tTrain Loss: 0.450 | Train Acc: 80.39%\n",
            "\t Val. Loss: 0.653 |  Val. Acc: 67.01%\n",
            "\tTrain Loss: 0.436 | Train Acc: 80.89%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 67.12%\n",
            "\tTrain Loss: 0.440 | Train Acc: 80.90%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 66.16%\n",
            "\tTrain Loss: 0.425 | Train Acc: 81.65%\n",
            "\t Val. Loss: 0.662 |  Val. Acc: 67.58%\n",
            "\tTrain Loss: 0.422 | Train Acc: 81.72%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 66.62%\n",
            "\tTrain Loss: 0.413 | Train Acc: 81.61%\n",
            "\t Val. Loss: 0.666 |  Val. Acc: 67.12%\n",
            "\tTrain Loss: 0.403 | Train Acc: 82.38%\n",
            "\t Val. Loss: 0.664 |  Val. Acc: 66.97%\n",
            "\tTrain Loss: 0.396 | Train Acc: 82.80%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 66.87%\n",
            "\tTrain Loss: 0.381 | Train Acc: 83.02%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 67.26%\n",
            "\tTrain Loss: 0.378 | Train Acc: 83.28%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 67.40%\n",
            "\tTrain Loss: 0.370 | Train Acc: 83.54%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 67.44%\n",
            "\tTrain Loss: 0.367 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 67.54%\n",
            "\tTrain Loss: 0.346 | Train Acc: 84.68%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 67.33%\n",
            "\tTrain Loss: 0.351 | Train Acc: 84.20%\n",
            "\t Val. Loss: 0.701 |  Val. Acc: 67.19%\n",
            "\tTrain Loss: 0.342 | Train Acc: 85.10%\n",
            "\t Val. Loss: 0.702 |  Val. Acc: 67.61%\n",
            "\tTrain Loss: 0.340 | Train Acc: 85.08%\n",
            "\t Val. Loss: 0.709 |  Val. Acc: 67.83%\n",
            "\tTrain Loss: 0.325 | Train Acc: 84.81%\n",
            "\t Val. Loss: 0.712 |  Val. Acc: 67.68%\n",
            "\tTrain Loss: 0.322 | Train Acc: 85.19%\n",
            "\t Val. Loss: 0.721 |  Val. Acc: 67.72%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8395ce2faaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-6465a3708811>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(epochs, model, train_iterator, valid_iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6465a3708811>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# zero accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# retrieve text and no. of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m   1510\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNhQggYQJrUm",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "lstm_model.load_state_dict(torch.load('checkpoint/twitter.t7', map_location=device))\n",
        "# predict\n",
        "test_loss, test_acc = evaluate(lstm_model, test_iterator, loss_func, report=True)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ocDF29euwWph"
      },
      "source": [
        "If the model is predicted perfectly confusion matrix should be diagonal which indicates values off the main diagonal representing incorrect prediction is zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QifVxbhqJrUm",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Visualizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-04T20:11:40.665155Z",
          "start_time": "2021-04-04T20:11:40.648151Z"
        },
        "id": "gH1wMUQVJrUm",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "vis_data_records_ig = []\n",
        "def forward(input, text_length):\n",
        "    return F.softmax(lstm_model(input, text_length)[0])\n",
        "lig = LayerIntegratedGradients(forward, lstm_model.embedding)\n",
        "def interpret_sentence(model, sentence, min_len = max_document_length, label = 0):\n",
        "    model.train()\n",
        "    h = model.init_hidden(1)\n",
        "    h500 = model.init_hidden(500)\n",
        "    text = preprocess(sentence)\n",
        "    actual_len = len(text)\n",
        "    if len(text) < min_len:\n",
        "        text += ['<pad>'] * (min_len - len(text))\n",
        "    indexed = [Text.vocab.stoi[t] for t in text]\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    input_indices = torch.tensor(indexed, device=device)\n",
        "    input_indices = input_indices.unsqueeze(0)\n",
        "    text_length = torch.tensor([actual_len], device=device)\n",
        "    # input_indices dim: [sequence_length]\n",
        "    seq_length = min_len\n",
        "\n",
        "    # predict\n",
        "    pred = F.softmax(model(input_indices, text_length, h)[0]).argmax(dim=1).item()\n",
        "    pred_ind = round(pred)\n",
        "\n",
        "    # generate reference indices for each sample\n",
        "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
        "\n",
        "    # compute attributions and approximation delta using layer integrated gradients\n",
        "    attributions_ig, delta = lig.attribute(input_indices, reference_indices,\n",
        "                                           n_steps=500,target=2-label, return_convergence_delta=True, additional_forward_args=text_length)\n",
        "\n",
        "    print(sentence, 'pred: ', {1:'positive', 0: 'netural', 2: 'negative'}[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
        "\n",
        "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
        "\n",
        "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
        "    attributions = attributions.sum(dim=2).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    attributions = attributions.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "    # storing couple samples in an array for visualization purposes\n",
        "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
        "        attributions,\n",
        "        pred,\n",
        "        {1:'positive', 0: 'netural', 2: 'negative'}[pred_ind],\n",
        "        {1:'positive', 0: 'netural', 2: 'negative'}[label],\n",
        "        {1:'positive', 0: 'netural', 2: 'negative'}[label],\n",
        "        attributions.sum(),\n",
        "        text,\n",
        "        delta))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wUrqYoqLz9ks"
      },
      "source": [
        "interpret_sentence(lstm_model, 'It was a fantastic performance !', label=1)\n",
        "interpret_sentence(lstm_model, 'Best film ever', label=1)\n",
        "interpret_sentence(lstm_model, 'Such a great show!', label=1)\n",
        "interpret_sentence(lstm_model, 'It was a horrible movie', label=2)\n",
        "interpret_sentence(lstm_model, 'I\\'ve never watched something as bad', label=2)\n",
        "interpret_sentence(lstm_model, 'It is a disgusting movie!', label=2)\n",
        "interpret_sentence(lstm_model, 'normal', label=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sheZvYeYz9ks"
      },
      "source": [
        "_ = visualization.visualize_text(vis_data_records_ig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3R8NdKcbz9kt"
      },
      "source": [
        "vis_word = []\n",
        "colorlist= []\n",
        "def interpret_word(model, word, min_len = max_document_length, label = 0):\n",
        "    model.train()\n",
        "    text = preprocess(word)\n",
        "    actual_len = 1\n",
        "    if len(text) < min_len:\n",
        "        text += ['<pad>'] * (min_len - len(text))\n",
        "    indexed = [Text.vocab.stoi[t] for t in text]\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    input_indices = torch.tensor(indexed, device=device)\n",
        "    input_indices = input_indices.unsqueeze(0)\n",
        "    text_length = torch.tensor([actual_len], device=device)\n",
        "    # input_indices dim: [sequence_length]\n",
        "    seq_length = min_len\n",
        "\n",
        "    # predict\n",
        "    pred = F.softmax(model(input_indices, text_length)[0]).cpu()\n",
        "\n",
        "\n",
        "    vis_word.append(pred.detach().numpy().squeeze(0))\n",
        "    colorlist.append({0:'#00ff00', 1: '#00ffff', 2:'#000000' }[pred.argmax(dim=1).item()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kMTrDK7sz9kt"
      },
      "source": [
        "for i in Text.vocab.itos:\n",
        "    interpret_word(lstm_model, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ndkX6219z9kt"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "words_top_ted_tsne = tsne.fit_transform(vis_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T15:55:28.003009Z",
          "start_time": "2021-04-05T15:55:27.883014Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yd79T06dz9kt"
      },
      "source": [
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"vector T-SNE for most polarized words\")\n",
        "\n",
        "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
        "                                    x2=words_top_ted_tsne[:,1],\n",
        "                                    names=Text.vocab.itos,\n",
        "                                    color=colorlist))\n",
        "\n",
        "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, fill_color=\"color\")\n",
        "\n",
        "word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
        "                       text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                       source=source, text_align='center',render_mode='canvas')\n",
        "# p.add_layout(word_labels)\n",
        "\n",
        "show(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T15:55:20.282440Z",
          "start_time": "2021-04-05T15:55:20.162442Z"
        },
        "id": "wWbpD19Dz9ku"
      },
      "source": [
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"vector T-SNE for most polarized words\")\n",
        "\n",
        "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
        "                                    x2=words_top_ted_tsne[:,1],\n",
        "                                    names=Text.vocab.itos,\n",
        "                                    color=colorlist))\n",
        "\n",
        "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, fill_color=\"color\")\n",
        "\n",
        "word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
        "                       text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                       source=source, text_align='center',render_mode='canvas')\n",
        "p.add_layout(word_labels)\n",
        "\n",
        "show(p)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}