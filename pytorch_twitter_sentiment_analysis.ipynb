{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "pytorch_twitter_sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "oYCfnhWzJrUI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Twitter Sentiment Analysis Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS1rkSnEJrUQ",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "cdbd5e4c-9d32-42f0-e8e4-c397f5b77100"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import imblearn\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.utils import tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torchtext.legacy import data\n",
    "# from torchtext import data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "! pip install captum bokeh spacy emot\n",
    "import captum\n",
    "import spacy\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, IntegratedGradients, LayerConductance\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "import emot\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "! python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en')\n",
    "%matplotlib inline"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
      "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
      "Requirement already satisfied: emot in /usr/local/lib/python3.7/dist-packages (2.1)\n",
      "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum) (1.8.1+cu101)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh) (2.8.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh) (2.11.3)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh) (20.9)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh) (7.1.2)\n",
      "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh) (5.1.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh) (3.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh) (3.7.4.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.2.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DETgMPgJrUS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "QwFJPG55JrUT",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "9d8b44f8-f467-484f-c72c-d50e5072e2dc"
   },
   "source": [
    "# !curl https://raw.githubusercontent.com/dipikabaad/Sentiment_Classification_with_RNN/master/Tweets.csv --create-dirs -o .pytorch/tweets/tweets.csv\n",
    "# !mkdir checkpoint\n",
    "df = pd.read_csv('.pytorch/tweets/Twitter_Data.csv')\n",
    "df.head()"
   ],
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          clean_text  category\n0  when modi promised “minimum government maximum...      -1.0\n1  talk all the nonsense and continue all the dra...       0.0\n2  what did just say vote for modi  welcome bjp t...       1.0\n3  asking his supporters prefix chowkidar their n...       1.0\n4  answer who among these the most powerful world...       1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>when modi promised “minimum government maximum...</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>talk all the nonsense and continue all the dra...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what did just say vote for modi  welcome bjp t...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>asking his supporters prefix chowkidar their n...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>answer who among these the most powerful world...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnZDU5kUJrUT"
   },
   "source": [
    "### Exploring features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "8iEEuqAuJrUT",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "2ba79036-b670-4547-90dd-e12bc2c63875"
   },
   "source": [
    "df.describe()"
   ],
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "            category\ncount  162973.000000\nmean        0.225436\nstd         0.781279\nmin        -1.000000\n25%         0.000000\n50%         0.000000\n75%         1.000000\nmax         1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>162973.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.225436</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.781279</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLQm2ZkvJrUU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "HLQhe0zgJrUU",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "0f9aab2b-3fa1-44ff-8df1-986582b55864"
   },
   "source": [
    "df.groupby('category').describe()"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "         clean_text                                                            \\\n              count unique                                                top   \ncategory                                                                        \n-1.0          35509  35509  the goal not clear confusion goal drop hint th...   \n 0.0          55211  55211  mosadai modi anayam for this judgement helps a...   \n 1.0          72249  72249  right strong govt can also ensure the escape r...   \n\n               \n         freq  \ncategory       \n-1.0        1  \n 0.0        1  \n 1.0        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">clean_text</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1.0</th>\n      <td>35509</td>\n      <td>35509</td>\n      <td>the goal not clear confusion goal drop hint th...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0.0</th>\n      <td>55211</td>\n      <td>55211</td>\n      <td>mosadai modi anayam for this judgement helps a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>72249</td>\n      <td>72249</td>\n      <td>right strong govt can also ensure the escape r...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgpw8FCZJrUV",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "4f3f2daf-ae91-48e9-fffd-642d6ceb8c47"
   },
   "source": [
    "df.info()"
   ],
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162980 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162976 non-null  object \n",
      " 1   category    162973 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oGU6704JrUV",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "4e722407-3c6d-47de-8cb3-708662868096"
   },
   "source": [
    "df.isnull().sum()"
   ],
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "clean_text    4\ncategory      7\ndtype: int64"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "QFUejj4jJrUV",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "12dcc85b-cfa3-4c0d-ca2f-2d40251f773b"
   },
   "source": [
    "df[df['clean_text'].str.len() < 2]"
   ],
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "      clean_text  category\n77224                  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>77224</th>\n      <td></td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "yZ6t1ICXJrUW",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "63d0c017-6780-4b79-aed9-e20dd8ee25a3"
   },
   "source": [
    "df[df.duplicated('clean_text')]"
   ],
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "       clean_text  category\n158694        NaN      -1.0\n159443        NaN       0.0\n160560        NaN       1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>158694</th>\n      <td>NaN</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>159443</th>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>160560</th>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "HHfQVsljJrUW",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "6f4c7d6e-3ced-4f97-b63b-20d0c97a1c1c"
   },
   "source": [
    "df.drop_duplicates('clean_text', inplace=True)\n",
    "df[df.duplicated('clean_text')]"
   ],
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [clean_text, category]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "y_GcsS8iJrUX",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "9d7dd307-2055-4be0-c01e-9a63b37d2433"
   },
   "source": [
    "df[['category', 'clean_text']].groupby('category').count().plot.bar()"
   ],
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x1f5983fc1c8>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRNRGUr1JrUX"
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_Sbn3-qJrUX"
   },
   "source": [
    "#### Steps\n",
    "1. One-hot encode output\n",
    "2. Replace tags and metion with a unique symbol\n",
    "3. Replace `emoji` and `emoticons` with their meaning\n",
    "4. Remove stop-words\n",
    "5. Remove punctuation and tokenize sentences\n",
    "6. Stemming each token"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "iy0yXqzYJrUY",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "d385cb7c-9d1c-4541-acab-89198582bc7e"
   },
   "source": [
    "\n",
    "condlist = [\n",
    "    df['category'] == 1, # pos\n",
    "    df['category'] == 0, # neu\n",
    "    df['category'] == -1 # neg\n",
    "]\n",
    "df['sentiment'] = np.select(condlist, [1,0,2])\n",
    "d = df[['clean_text', 'sentiment']]\n",
    "d.rename(columns={'clean_text': 'text'}, inplace=True)\n",
    "d.head()"
   ],
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\frame.py:4304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                text  sentiment\n0  when modi promised “minimum government maximum...          2\n1  talk all the nonsense and continue all the dra...          0\n2  what did just say vote for modi  welcome bjp t...          1\n3  asking his supporters prefix chowkidar their n...          1\n4  answer who among these the most powerful world...          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>when modi promised “minimum government maximum...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>talk all the nonsense and continue all the dra...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what did just say vote for modi  welcome bjp t...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>asking his supporters prefix chowkidar their n...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>answer who among these the most powerful world...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "xHC-GTGIJrUY",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "06bcb3ff-7a72-4dae-ee92-78f0ec643909"
   },
   "source": [
    "def emoji_helper(text):\n",
    "    clean_mean = lambda x:  x.replace('-', '_').replace(':', ' ')\n",
    "    for emoti in emot.emo_unicode.EMOTICONS:\n",
    "        if emoti in text:\n",
    "            text = text.replace(emoti, clean_mean(emot.emo_unicode.EMOTICONS.get(emoti, '')))\n",
    "\n",
    "    for emoti in emot.emo_unicode.UNICODE_EMO:\n",
    "        if emoti in text:\n",
    "            text = text.replace(emoti, clean_mean(emot.emo_unicode.UNICODE_EMO.get(emoti, '')))\n",
    "\n",
    "    for emoti in emot.emo_unicode.EMOTICONS_EMO:\n",
    "        if emoti in text:\n",
    "            text = text.replace(emoti, clean_mean(emot.emo_unicode.EMOTICONS_EMO.get(emoti, '')).replace(' ','_'))\n",
    "    return text\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return [porter_stemmer.stem(word) for word in\n",
    "        simple_preprocess(remove_stopwords(emoji_helper(re.sub(r'\\s*([@#][\\w_-]+)', '', str(x)))), deacc=True)\n",
    "    ]\n",
    "\n",
    "d['text'] = d['text'].apply(func=lambda x:preprocess(x))\n",
    "\n",
    "d"
   ],
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                     text  sentiment\n0       [modi, promis, minimum, govern, maximum, gover...          2\n1             [talk, nonsens, continu, drama, vote, modi]          0\n2       [vote, modi, welcom, bjp, told, rahul, main, c...          1\n3       [ask, support, prefix, chowkidar, name, modi, ...          1\n4       [answer, power, world, leader, todai, trump, p...          1\n...                                                   ...        ...\n162975  [crore, paid, neerav, modi, recov, congress, l...          2\n162976  [dear, rss, terrorist, payal, gawar, modi, kil...          2\n162977                     [cover, interact, forum, left]          0\n162978  [big, project, came, india, modi, dream, proje...          0\n162979  [listen, like, gurukul, disciplin, maintain, n...          1\n\n[162977 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[modi, promis, minimum, govern, maximum, gover...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[talk, nonsens, continu, drama, vote, modi]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[vote, modi, welcom, bjp, told, rahul, main, c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[ask, support, prefix, chowkidar, name, modi, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[answer, power, world, leader, todai, trump, p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>162975</th>\n      <td>[crore, paid, neerav, modi, recov, congress, l...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>162976</th>\n      <td>[dear, rss, terrorist, payal, gawar, modi, kil...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>162977</th>\n      <td>[cover, interact, forum, left]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>162978</th>\n      <td>[big, project, came, india, modi, dream, proje...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>162979</th>\n      <td>[listen, like, gurukul, disciplin, maintain, n...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>162977 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1lsg8zVJrUY"
   },
   "source": [
    "#### Analyze review length\n",
    "Here we remove the outliers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nE-zLQLWJrUZ",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "dc2407f2-9249-433c-b836-7dcb20cceb01"
   },
   "source": [
    "d['text'].str.len().describe()"
   ],
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "count    162977.000000\nmean         12.894905\nstd           6.987476\nmin           0.000000\n25%           7.000000\n50%          12.000000\n75%          18.000000\nmax          42.000000\nName: text, dtype: float64"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "241NoGKyJrUZ",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "d948c451-8960-4cd4-b003-4bf33c618c33"
   },
   "source": [
    "d['text'].str.len().hist()"
   ],
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x1f598a17988>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "YKCZ7SYYJrUZ",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "70c99c6c-39e2-4dc0-bc9d-6ea4386a4833"
   },
   "source": [
    "d = d[ (2 < d['text'].str.len()) & (d['text'].str.len() < 24) ]\n",
    "d['text'].str.len().hist()"
   ],
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x1f598aaa408>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGONJREFUeJzt3X+M3PWd3/HnuyZQDidgQtg6Nq2J5CABbjm8IrRponVJwJBcTKImBSEwPyKHKJwSyVUxTXugcKjkLiRS7iitc1iYuxwLOkKwiCnxIfboSZCAOYJxCGFNfMnarq1gY9gEkTp994/57N1kvzM7Ozs7O7Ph+ZBG853P9/P9ft/z3e9+X/v9MbORmUiSVO+f9LoASVL/MRwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjiq1wXM1EknnZTLli1rOO4Xv/gFxx133NwWNA39Whf0b23W1R7ras9bsa7t27f/PDPf1bJjZs7Lx8qVK7OZxx57rOm4XurXujL7tzbrao91teetWBfwdE5jH+tpJUlSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUsW8/foMtWfZhu9MOX79iiNc2aLPTOy+9SOzPk9J3eeRgySpwnCQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVLT8EFxGbgI8CBzLzzNJ2L3Ba6XIC8GpmnhURy4AXgBfLuCcz89oyzUrgLuBYYCvw+czMiDgRuBdYBuwGPpWZh2bhvakPtPrwXSudfDjPD+BJMzedI4e7gNX1DZn5HzLzrMw8C7gf+Fbd6F0T4yaCobgDWAcsL4+JeW4AHs3M5cCj5bUkqYdahkNmPg4cbDQuIgL4FHDPVPOIiMXAOzLzifIPru8GLi6j1wCby/DmunZJUo9EbV/dolPtdNFDE6eV6to/CHw1Mwfr+u0Efgy8BvyXzPzfETEI3JqZHyr9PgBcn5kfjYhXM/OEunkeysxFTepYR+3og4GBgZXDw8MN6x0fH2fhwoUt39dc62VdO/YcnnL8wLGw/405KqYNndS1Ysnxs1tMHbex9lhXe7pZ16pVq7ZP7LOn0ukX713Kbx417AP+eWa+Uq4xfDsizgCiwbStU2nyBJkbgY0Ag4ODOTQ01LDfyMgIzcb1Ui/ranXefv2KI9y2o/++h7GTunZfNjS7xdRxG2uPdbWnH+qa8d4gIo4CPgGsnGjLzDeBN8vw9ojYBbwXGAOW1k2+FNhbhvdHxOLM3FdOPx2YaU2SpNnRya2sHwJ+lJljEw0R8a6IWFCG30PtwvPLmbkPeD0izi3XKa4AHiyTbQHWluG1de2SpB5pGQ4RcQ/wBHBaRIxFxDVl1CVUL0R/EHguIn4A/BVwbWZOXMz+LPBnwCiwC3i4tN8KfDgiXgI+XF5Lknqo5WmlzLy0SfuVDdrup3Zra6P+TwNnNmh/BTivVR2/DXbsOdyVf6gjSbPNT0hLkioMB0lSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklTRf/9RXpoly7r4j5XWrzjS9B837b71I11brjRXPHKQJFVM539Ib4qIAxHxfF3bTRGxJyKeLY+L6sbdEBGjEfFiRFxQ1766tI1GxIa69lMj4nsR8VJE3BsRR8/mG5QktW86Rw53AasbtH8tM88qj60AEXE6cAlwRpnmv0fEgohYANwOXAicDlxa+gJ8ucxrOXAIuKaTNyRJ6lzLcMjMx4GD05zfGmA4M9/MzJ8Ao8A55TGamS9n5q+AYWBNRATw74C/KtNvBi5u8z1IkmZZJ9ccrouI58ppp0WlbQnws7o+Y6WtWfs7gVcz88ikdklSD830bqU7gJuBLM+3AVcD0aBv0jiEcor+DUXEOmAdwMDAACMjIw37jY+PNx3XSwPH1u5y6Uf9Wtt8rKuX216/bvvW1Z5+qGtG4ZCZ+yeGI+IbwEPl5RhwSl3XpcDeMtyo/efACRFxVDl6qO/faLkbgY0Ag4ODOTQ01LDfyMgIzcb10p9880Fu29Gfdw+vX3GkL2ubj3Xtvmxoboup06/bvnW1px/qmtFppYhYXPfy48DEnUxbgEsi4piIOBVYDnwfeApYXu5MOpraRestmZnAY8C/L9OvBR6cSU2SpNnT8k+yiLgHGAJOiogx4EZgKCLOonYKaDfwGYDM3BkR9wE/BI4An8vMX5f5XAc8AiwANmXmzrKI64HhiPhD4O+AO2ft3UmSZqRlOGTmpQ2am+7AM/MW4JYG7VuBrQ3aX6Z2N5MkqU/038lcSZoHftu/nsWvz5AkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFX4CWlplnXzk7Ot3LX6uJ4tW79dPHKQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVhoMkqaLlh+AiYhPwUeBAZp5Z2v4Y+D3gV8Au4KrMfDUilgEvAC+WyZ/MzGvLNCuBu4Bjqf0v6c9nZkbEicC9wDJgN/CpzDw0O2+vsV59SGn9ip4sVpLaNp0jh7uA1ZPatgFnZua/BH4M3FA3bldmnlUe19a13wGsA5aXx8Q8NwCPZuZy4NHyWpLUQy3DITMfBw5OavtuZh4pL58Elk41j4hYDLwjM5/IzATuBi4uo9cAm8vw5rp2SVKPzMY1h6uBh+tenxoRfxcRfxMRHyhtS4Cxuj5jpQ1gIDP3AZTnk2ehJklSB6L2h3yLTrVrCQ9NXHOoa/8iMAh8olw/OAZYmJmvlGsM3wbOAE4D/ltmfqhM9wHgP2Xm70XEq5l5Qt08D2XmoiZ1rKN2aoqBgYGVw8PDDesdHx9n4cKFTd/Pjj2HW77nbhg4Fva/0ZNFt9SvtVlXe049fsGU236vtPqd7JVO6urmfmSq7WvFkuM7mveqVau2Z+Zgq34z/lbWiFhL7UL1eeVUEZn5JvBmGd4eEbuA91I7Uqg/9bQU2FuG90fE4szcV04/HWi2zMzcCGwEGBwczKGhoYb9RkZGaDYO4MqeXZA+wm07+vOLcPu1Nutqz12rj5ty2++VVr+TvdJJXd3cj0y1fe2+bKhry603o9NKEbEauB74WGb+sq79XRGxoAy/h9qF55fL6aLXI+LciAjgCuDBMtkWYG0ZXlvXLknqkencynoPMAScFBFjwI3U7k46BthW29f/wy2rHwS+FBFHgF8D12bmxMXsz/KPt7I+zD9ep7gVuC8irgF+CnxyVt6Z9Ba0Y8/hnhwZ7771I3O+THVXy3DIzEsbNN/ZpO/9wP1Nxj0NnNmg/RXgvFZ1SJLmjp+QliRVGA6SpArDQZJUYThIkioMB0lSheEgSaowHCRJFf33+X9J806r/5GyfsWRrn04zw/gdYdHDpKkCo8cJM1rnfxnx24e0cx3HjlIkioMB0lSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqphUOEbEpIg5ExPN1bSdGxLaIeKk8LyrtERFfj4jRiHguIs6um2Zt6f9SRKyta18ZETvKNF+PiJjNNylJas90jxzuAlZPatsAPJqZy4FHy2uAC4Hl5bEOuANqYQLcCLwPOAe4cSJQSp91ddNNXpYkaQ5NKxwy83Hg4KTmNcDmMrwZuLiu/e6seRI4ISIWAxcA2zLzYGYeArYBq8u4d2TmE5mZwN1185Ik9UAn1xwGMnMfQHk+ubQvAX5W12+stE3VPtagXZLUI934VtZG1wtyBu3VGUeso3b6iYGBAUZGRhoWMD4+3nQc1L6JsRcGju3dslvp19qsqz3W1Z75WNdU+7bZ1Ek47I+IxZm5r5waOlDax4BT6votBfaW9qFJ7SOlfWmD/hWZuRHYCDA4OJhDQ0ONujEyMkKzcUDPvqJ3/Yoj3LajP78lvV9rs672WFd75mNduy8bmpMaOjmttAWYuONoLfBgXfsV5a6lc4HD5bTTI8D5EbGoXIg+H3ikjHs9Is4tdyldUTcvSVIPTCsyI+Iean/1nxQRY9TuOroVuC8irgF+CnyydN8KXASMAr8ErgLIzIMRcTPwVOn3pcycuMj9WWp3RB0LPFwekqQemVY4ZOalTUad16BvAp9rMp9NwKYG7U8DZ06nFklS9/kJaUlSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVMw6HiDgtIp6te7wWEV+IiJsiYk9d+0V109wQEaMR8WJEXFDXvrq0jUbEhk7flCSpM0fNdMLMfBE4CyAiFgB7gAeAq4CvZeZX6vtHxOnAJcAZwLuBv46I95bRtwMfBsaApyJiS2b+cKa1SZI6M+NwmOQ8YFdm/n1ENOuzBhjOzDeBn0TEKHBOGTeamS8DRMRw6Ws4SFKPRGZ2PpOITcAzmfmnEXETcCXwGvA0sD4zD0XEnwJPZuZflGnuBB4us1idmZ8u7ZcD78vM6xosZx2wDmBgYGDl8PBww3rGx8dZuHBh03p37Dk8k7fZsYFjYf8bPVl0S/1am3W1x7raMx/rWrHk+I7mvWrVqu2ZOdiqX8dHDhFxNPAx4IbSdAdwM5Dl+TbgaqDRIUXS+LpHw8TKzI3ARoDBwcEcGhpqWNPIyAjNxgFcueE7Tcd10/oVR7htx2wdrM2ufq3NutpjXe2Zj3XtvmxoTmqYjbVyIbWjhv0AE88AEfEN4KHycgw4pW66pcDeMtysXZLUA7NxK+ulwD0TLyJicd24jwPPl+EtwCURcUxEnAosB74PPAUsj4hTy1HIJaWvJKlHOjpyiIjfoXaX0Wfqmv8oIs6idmpo98S4zNwZEfdRu9B8BPhcZv66zOc64BFgAbApM3d2UpckqTMdhUNm/hJ456S2y6fofwtwS4P2rcDWTmqRJM0ePyEtSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVhoMkqaLjcIiI3RGxIyKejYinS9uJEbEtIl4qz4tKe0TE1yNiNCKei4iz6+aztvR/KSLWdlqXJGnmZuvIYVVmnpWZg+X1BuDRzFwOPFpeA1wILC+PdcAdUAsT4EbgfcA5wI0TgSJJmnvdOq20BthchjcDF9e13501TwInRMRi4AJgW2YezMxDwDZgdZdqkyS1EJnZ2QwifgIcAhL4n5m5MSJezcwT6vocysxFEfEQcGtm/m1pfxS4HhgC/mlm/mFp/6/AG5n5lUnLWkftiIOBgYGVw8PDDWsaHx9n4cKFTWvesefwTN9uRwaOhf1v9GTRLfVrbdbVHutqz3ysa8WS4zua96pVq7bXneVp6qiOllLz/szcGxEnA9si4kdT9I0GbTlF+282ZG4ENgIMDg7m0NBQw4WMjIzQbBzAlRu+M0WJ3bN+xRFu2zEbq3z29Wtt1tUe62rPfKxr92VDc1JDx6eVMnNveT4APEDtmsH+crqI8nygdB8DTqmbfCmwd4p2SVIPdBQOEXFcRLx9Yhg4H3ge2AJM3HG0FniwDG8Brih3LZ0LHM7MfcAjwPkRsahciD6/tEmSeqDT46kB4IGImJjXX2bm/4qIp4D7IuIa4KfAJ0v/rcBFwCjwS+AqgMw8GBE3A0+Vfl/KzIMd1iZJmqGOwiEzXwb+VYP2V4DzGrQn8Lkm89oEbOqkHknS7PAT0pKkCsNBklRhOEiSKgwHSVKF4SBJqjAcJEkVhoMkqcJwkCRVGA6SpArDQZJUYThIkioMB0lSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVDHjcIiIUyLisYh4ISJ2RsTnS/tNEbEnIp4tj4vqprkhIkYj4sWIuKCufXVpG42IDZ29JUlSpzr5H9JHgPWZ+UxEvB3YHhHbyrivZeZX6jtHxOnAJcAZwLuBv46I95bRtwMfBsaApyJiS2b+sIPaJEkdmHE4ZOY+YF8Zfj0iXgCWTDHJGmA4M98EfhIRo8A5ZdxoZr4MEBHDpa/hIEk9MivXHCJiGfC7wPdK03UR8VxEbIqIRaVtCfCzusnGSluzdklSj0RmdjaDiIXA3wC3ZOa3ImIA+DmQwM3A4sy8OiJuB57IzL8o090JbKUWUBdk5qdL++XAOZn5+w2WtQ5YBzAwMLByeHi4YU3j4+MsXLiwac079hye6dvtyMCxsP+Nniy6pX6tzbraY13tmY91rVhyfEfzXrVq1fbMHGzVr5NrDkTE24D7gW9m5rcAMnN/3fhvAA+Vl2PAKXWTLwX2luFm7b8hMzcCGwEGBwdzaGioYV0jIyM0Gwdw5YbvNB3XTetXHOG2HR2t8q7p19qsqz3W1Z75WNfuy4bmpIZO7lYK4E7ghcz8al374rpuHweeL8NbgEsi4piIOBVYDnwfeApYHhGnRsTR1C5ab5lpXZKkznUSme8HLgd2RMSzpe0/A5dGxFnUTivtBj4DkJk7I+I+aheajwCfy8xfA0TEdcAjwAJgU2bu7KAuSVKHOrlb6W+BaDBq6xTT3ALc0qB961TTSZLmlp+QliRVGA6SpArDQZJUYThIkioMB0lSheEgSaowHCRJFYaDJKnCcJAkVRgOkqQKw0GSVGE4SJIqDAdJUoXhIEmqMBwkSRWGgySpwnCQJFUYDpKkCsNBklTRN+EQEasj4sWIGI2IDb2uR5LeyvoiHCJiAXA7cCFwOnBpRJze26ok6a2rL8IBOAcYzcyXM/NXwDCwpsc1SdJbVr+EwxLgZ3Wvx0qbJKkHIjN7XQMR8Unggsz8dHl9OXBOZv7+pH7rgHXl5WnAi01meRLw8y6V24l+rQv6tzbrao91teetWNe/yMx3tep0VJcW3q4x4JS610uBvZM7ZeZGYGOrmUXE05k5OHvlzY5+rQv6tzbrao91tce6muuX00pPAcsj4tSIOBq4BNjS45ok6S2rL44cMvNIRFwHPAIsADZl5s4elyVJb1l9EQ4AmbkV2DpLs2t56qlH+rUu6N/arKs91tUe62qiLy5IS5L6S79cc5Ak9ZF5Gw4RcUpEPBYRL0TEzoj4fIM+QxFxOCKeLY8/mKPadkfEjrLMpxuMj4j4evmqkOci4uw5qOm0uvXwbES8FhFfmNRnztZXRGyKiAMR8Xxd24kRsS0iXirPi5pMu7b0eSki1s5BXX8cET8qP6sHIuKEJtNO+XPvQl03RcSeup/XRU2m7dpX0zSp6966mnZHxLNNpu3K+mq2b+j19jVFXT3fvhrKzHn5ABYDZ5fhtwM/Bk6f1GcIeKgHte0GTppi/EXAw0AA5wLfm+P6FgD/h9r9zj1ZX8AHgbOB5+va/gjYUIY3AF9uMN2JwMvleVEZXtTlus4HjirDX25U13R+7l2o6ybgP07jZ70LeA9wNPCDyb8ns13XpPG3AX8wl+ur2b6h19vXFHX1fPtq9Ji3Rw6ZuS8znynDrwMvMH8+Vb0GuDtrngROiIjFc7j884Bdmfn3c7jM35CZjwMHJzWvATaX4c3AxQ0mvQDYlpkHM/MQsA1Y3c26MvO7mXmkvHyS2udw5lST9TUdXf1qmqnqiogAPgXcM1vLm2ZNzfYNPd2+mtXVD9tXI/M2HOpFxDLgd4HvNRj9ryPiBxHxcEScMUclJfDdiNgetU91T9brrwu5hOa/sL1YXxMGMnMf1H6RgJMb9On1urua2lFfI61+7t1wXTkdsanJaZJerq8PAPsz86Um47u+vibtG/pm+5pin9U321ff3Mo6UxGxELgf+EJmvjZp9DPUTp2Ml/Ox3waWz0FZ78/MvRFxMrAtIn5U/sL6h7IbTDMnt41F7UOGHwNuaDC6V+urHb1cd18EjgDfbNKl1c99tt0B3Ezt/d9M7RTO1ZP69Gx9AZcy9VFDV9fX5H1D7UCm9WQN2mZ1fTXbZ/Xb9jWvjxwi4m3UVvI3M/Nbk8dn5muZOV6GtwJvi4iTul1XZu4tzweAB6gd2teb1teFdMmFwDOZuX/yiF6trzr7J06vlecDDfr0ZN2VC5MfBS7LcgJ4smn83GdVZu7PzF9n5v8DvtFkeb1aX0cBnwDubdanm+uryb6h59tXs31WP25f8zYcyvnMO4EXMvOrTfr8s9KPiDiH2vt9pct1HRcRb58Ypnax6flJ3bYAV0TNucDhicPdOdD0r7lerK9JtgATd4esBR5s0OcR4PyIWFROo5xf2romIlYD1wMfy8xfNukznZ/7bNdVf53q402W16uvpvkQ8KPMHGs0spvra4p9Q0+3r2Z19ev2NSdXvbvxAP4ttcO954Bny+Mi4Frg2tLnOmAntTs0ngT+zRzU9Z6yvB+UZX+xtNfXFdT+udEuYAcwOEfr7Heo7eyPr2vryfqiFlD7gP9L7a+1a4B3Ao8CL5XnE0vfQeDP6qa9Ghgtj6vmoK5RauehJ7az/1H6vhvYOtXPvct1/XnZfp6jtuNbPLmu8voianfG7JqLukr7XRPbVV3fOVlfU+wberp9TVFXz7evRg8/IS1Jqpi3p5UkSd1jOEiSKgwHSVKF4SBJqjAcJEkVhoMkqcJwkCRVGA6SpIr/D7w9xe0cebK7AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FTBryPnJrUa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating vocab"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j6jBsOu6JrUa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "max_document_length = d['text'].str.len().max()  # each sentence has until 100 words\n",
    "max_size = 5000\n",
    "Text = data.Field(batch_first=True, tokenize=lambda x: x, include_lengths=True, fix_length=max_document_length)\n",
    "Label = data.Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)\n",
    "fields = [('text', Text), ('labels', Label)]"
   ],
   "execution_count": 93,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOIRUDjzJrUa",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "83ec3f9d-e997-46ca-a3f7-ff710a9a8b5d"
   },
   "source": [
    "class DataFrameDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, text_field, label_field, is_test=False, **kwargs):\n",
    "        fields = [('text', text_field), ('labels', label_field)]\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.sentiment\n",
    "            text = row.text\n",
    "            examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, train_df, test_df=None, **kwargs):\n",
    "        train_data, test_data = (None, None)\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), text_field, label_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), text_field, label_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, test_data) if d is not None)\n",
    "test_size = 0.2 # split percentage to train\\validation data\n",
    "X_train,X_test,y_train,y_test = train_test_split(d['text'].index,d['sentiment'], test_size=test_size, random_state=0, stratify=d['sentiment'])\n",
    "train_df = d.loc[X_train.values]\n",
    "test_df = d.loc[X_test.values]\n",
    "train_ds, test_ds = DataFrameDataset.splits(\n",
    "    text_field=Text, label_field=Label, train_df=train_df, test_df=test_df)\n",
    "vars(test_ds[0])"
   ],
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "{'text': ['countri',\n  'forward',\n  'economi',\n  'remov',\n  'poverti',\n  'protect',\n  'countri',\n  'remov',\n  'modi',\n  'shri'],\n 'labels': 1}"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rzlLLUsKDPJ"
   },
   "source": [
    "### Checking how balance is our testset in comparison to trainset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8fU_1ta2JuSZ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "outputId": "5d18405b-0d37-4c98-8ab1-fca7c76b538a"
   },
   "source": [
    "test_df.groupby('sentiment').count()/test_df['sentiment'].count()*100"
   ],
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "                text\nsentiment           \n0          34.421928\n1          44.208927\n2          21.369144",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>sentiment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34.421928</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44.208927</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.369144</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W-8DkMpgJ8Nz",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "outputId": "1ede3cf6-6168-4fd0-edcd-ab43660b7fc8"
   },
   "source": [
    "train_df.groupby('sentiment').count()/train_df['sentiment'].count()*100"
   ],
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "                text\nsentiment           \n0          34.423089\n1          44.206720\n2          21.370192",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>sentiment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34.423089</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44.206720</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.370192</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SFHEes6ewWpa",
    "outputId": "af82c2c5-f1ea-44be-83af-3330eec8e190",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "items = train_df.groupby('sentiment').count().to_numpy()\n",
    "neu, pos, neg = items[0][0], items[1][0], items[2][0]\n",
    "total = train_df.count()[0]\n",
    "weight_for_0 = (1 / neu)*(total)/2.0\n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "weight_for_2 = (1 / neg)*(total)/2.0\n",
    "print(weight_for_0, weight_for_1, weight_for_2)"
   ],
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.452513476244202 1.1310497647449287 2.339707604700941\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L4QWhGExJrUb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Text.build_vocab(train_ds, test_ds, max_size=max_size)\n",
    "Label.build_vocab(train_ds)\n",
    "vocab_size = len(Text.vocab)"
   ],
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fm69dUmTJrUb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "PAD_IND = Text.vocab.stoi['pad']\n",
    "# captum\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND) # create a reference (aka baseline) for the sentences and its constituent parts, tokens"
   ],
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5xCcMgXJrUb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjpQpWbkJrUb",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "8df6d548-7ad3-4a69-c332-94b1b29e0809"
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zFri3ivlJrUc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    # define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, output_dim, n_layers,\n",
    "                 bidirectional, dropout, pad_index):\n",
    "        # Constructor\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.bidirectional = bidirectional\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
    "\n",
    "        # lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim1,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim1 * 2, hidden_dim2)\n",
    "        self.fc2 = nn.Linear(hidden_dim2, output_dim)\n",
    "        self.relu = nn.SELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        # activation function\n",
    "        self.act = nn.Softmax() #\\ F.log_softmax(outp)\n",
    "\n",
    "    def forward(self, text, text_lengths, hid=None):\n",
    "        # text = [batch size,sent_length]\n",
    "        if hid == None:\n",
    "            hid = self.init_hidden(text.shape[0])\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [batch size, sent_len, emb dim]\n",
    "\n",
    "        # packed sequence\n",
    "        packed_embedded = pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True) # unpad\n",
    "\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded, hid)\n",
    "        # packed_output shape = (batch, seq_len, num_directions * hidden_size)\n",
    "        # hidden shape  = (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        # concat the final forward and backward hidden state\n",
    "        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        # output, output_lengths = pad_packed_sequence(packed_output)  # pad the sequence to the max length in the batch\n",
    "        cat = self.dropout1(cat)\n",
    "        rel = self.relu(cat)\n",
    "        dense1 = self.fc1(rel)\n",
    "\n",
    "        drop = self.dropout(dense1)\n",
    "        preds = self.fc2(drop)\n",
    "\n",
    "        # Final activation function\n",
    "        # preds = self.act(preds)\n",
    "        # preds = preds.argmax(dim=1).unsqueeze(0)\n",
    "        return preds, (hidden, cell)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (torch.zeros(self.n_layers*(2 if self.bidirectional else 1), batch_size, self.hidden_dim1).to(device),\n",
    "                  torch.zeros(self.n_layers*(2 if self.bidirectional else 1), batch_size, self.hidden_dim1).to(device))\n",
    "\n",
    "        return hidden"
   ],
   "execution_count": 101,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zLwnk5UJrUg",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "6c557f6e-08c1-4e84-bd9a-1cd6754455af"
   },
   "source": [
    "\n",
    "# hyper-parameters:\n",
    "lr = 1e-4\n",
    "batch_size = 50\n",
    "dropout_keep_prob = 0.5\n",
    "embedding_size = 300\n",
    "seed = 0\n",
    "clip=5\n",
    "num_classes = 3\n",
    "num_hidden_nodes = 93\n",
    "hidden_dim2 = 512\n",
    "num_layers = 2  # LSTM layers\n",
    "bi_directional = True\n",
    "num_epochs = 100\n",
    "\n",
    "pad_index = Text.vocab.stoi[Text.pad_token]\n",
    "\n",
    "# Build the model\n",
    "lstm_model = LSTM(vocab_size, embedding_size, num_hidden_nodes, hidden_dim2 , num_classes, num_layers,\n",
    "                  bi_directional, dropout_keep_prob, pad_index)\n",
    "lstm_model.to(device)\n",
    "print(lstm_model)"
   ],
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(5002, 300, padding_idx=1)\n",
      "  (lstm): LSTM(300, 93, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=186, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (relu): SELU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (act): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLmmdfsyJrUk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tESutgn6JrUk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "train_iterator, test_iterator = data.BucketIterator.splits((train_ds, test_ds),\n",
    "                                                           batch_size=batch_size,\n",
    "                                                           sort_key=lambda x: len(x.text),\n",
    "                                                           # Sort the batches by text length size\n",
    "                                                           sort_within_batch=True,\n",
    "                                                           device=device,\n",
    "                                                           )"
   ],
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ne_LiAoSJrUk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def accuracy(probs, target):\n",
    "    winners = probs.argmax(dim=1)\n",
    "    corrects = (winners == target)\n",
    "    accuracy = corrects.sum().float() / float(target.size(0))\n",
    "    return accuracy\n",
    "\n",
    "def plot_cm(y_true, y_pred, target_names):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=target_names)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sb.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    h = model.init_hidden(batch_size)\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "        # retrieve text and no. of words\n",
    "        text, text_lengths = batch.text\n",
    "        if (text.shape[0], text.shape[1]) != (batch_size, max_document_length):\n",
    "            continue\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        predictions, h = model(text, text_lengths, h)\n",
    "        loss = criterion(predictions, batch.labels.squeeze())\n",
    "\n",
    "        acc = accuracy(predictions, batch.labels)\n",
    "\n",
    "        # perform backpropagation\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, report=False):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    report_pred_test =[]\n",
    "    report_label_test =[]\n",
    "\n",
    "    model.eval()\n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            if (text.shape[0], text.shape[1]) != (batch_size, max_document_length):\n",
    "                continue\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            predictions, val_h = model(text, text_lengths, val_h)\n",
    "\n",
    "            loss = criterion(predictions, batch.labels)\n",
    "\n",
    "            acc = accuracy(predictions, batch.labels)\n",
    "            if report:\n",
    "                report_pred_test.extend(predictions.argmax(dim=1).cpu())\n",
    "                report_label_test.extend(batch.labels.cpu())\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    if report:\n",
    "        print(classification_report(report_label_test, report_pred_test, target_names=['neutral', 'positive', 'negative']))\n",
    "        plot_cm(report_label_test, report_pred_test, target_names=[0, 1, 2])\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def run_train(epochs, model, train_iterator, valid_iterator, optimizer, criterion):\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train the model\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "\n",
    "        # evaluate the model\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        # save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'checkpoint/twitter.t7')\n",
    "\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')"
   ],
   "execution_count": 104,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aPadIekjJrUl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# loss function\n",
    "loss_func = nn.CrossEntropyLoss(weight=torch.tensor([weight_for_0, weight_for_1, weight_for_2], dtype=torch.float32, device=device))\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
   ],
   "execution_count": 105,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IXSVKXpkJrUl",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "66d4f20d-bc97-437a-91a1-fd6647e921a5"
   },
   "source": [
    "run_train(num_epochs, lstm_model, train_iterator, test_iterator, optimizer, loss_func)"
   ],
   "execution_count": 106,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-106-8395ce2faaf6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mrun_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlstm_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_iterator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_iterator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_func\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-104-6465a3708811>\u001B[0m in \u001B[0;36mrun_train\u001B[1;34m(epochs, model, train_iterator, valid_iterator, optimizer, criterion)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m         \u001B[1;31m# train the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m         \u001B[0mtrain_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_iterator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     93\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m         \u001B[1;31m# evaluate the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-104-6465a3708811>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, iterator, optimizer, criterion)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[1;31m# perform backpropagation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m         \u001B[1;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclip_grad_norm_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclip\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    244\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 245\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    145\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 147\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zNhQggYQJrUm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "lstm_model.load_state_dict(torch.load('checkpoint/twitter.t7', map_location=device))\n",
    "# predict\n",
    "test_loss, test_acc = evaluate(lstm_model, test_iterator, loss_func, report=True)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ocDF29euwWph"
   },
   "source": [
    "If the model is predicted perfectly confusion matrix should be diagonal which indicates values off the main diagonal representing incorrect prediction is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QifVxbhqJrUm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T20:11:40.665155Z",
     "start_time": "2021-04-04T20:11:40.648151Z"
    },
    "id": "gH1wMUQVJrUm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "vis_data_records_ig = []\n",
    "def forward(input, text_length):\n",
    "    return F.softmax(lstm_model(input, text_length)[0])\n",
    "lig = LayerIntegratedGradients(forward, lstm_model.embedding)\n",
    "def interpret_sentence(model, sentence, min_len = max_document_length, label = 0):\n",
    "    model.train()\n",
    "    h = model.init_hidden(1)\n",
    "    h500 = model.init_hidden(500)\n",
    "    text = preprocess(sentence)\n",
    "    actual_len = len(text)\n",
    "    if len(text) < min_len:\n",
    "        text += ['<pad>'] * (min_len - len(text))\n",
    "    indexed = [Text.vocab.stoi[t] for t in text]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    input_indices = torch.tensor(indexed, device=device)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "    text_length = torch.tensor([actual_len], device=device)\n",
    "    # input_indices dim: [sequence_length]\n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = F.softmax(model(input_indices, text_length, h)[0]).argmax(dim=1).item()\n",
    "    pred_ind = round(pred)\n",
    "\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(input_indices, reference_indices,\n",
    "                                           n_steps=500,target=2-label, return_convergence_delta=True, additional_forward_args=text_length)\n",
    "\n",
    "    print(sentence, 'pred: ', {1:'positive', 0: 'netural', 2: 'negative'}[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "        attributions,\n",
    "        pred,\n",
    "        {1:'positive', 0: 'netural', 2: 'negative'}[pred_ind],\n",
    "        {1:'positive', 0: 'netural', 2: 'negative'}[label],\n",
    "        {1:'positive', 0: 'netural', 2: 'negative'}[label],\n",
    "        attributions.sum(),\n",
    "        text,\n",
    "        delta))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wUrqYoqLz9ks"
   },
   "source": [
    "interpret_sentence(lstm_model, 'It was a fantastic performance !', label=1)\n",
    "interpret_sentence(lstm_model, 'Best film ever', label=1)\n",
    "interpret_sentence(lstm_model, 'Such a great show!', label=1)\n",
    "interpret_sentence(lstm_model, 'It was a horrible movie', label=2)\n",
    "interpret_sentence(lstm_model, 'I\\'ve never watched something as bad', label=2)\n",
    "interpret_sentence(lstm_model, 'It is a disgusting movie!', label=2)\n",
    "interpret_sentence(lstm_model, 'normal', label=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sheZvYeYz9ks"
   },
   "source": [
    "_ = visualization.visualize_text(vis_data_records_ig)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3R8NdKcbz9kt"
   },
   "source": [
    "vis_word = []\n",
    "colorlist= []\n",
    "def interpret_word(model, word, min_len = max_document_length, label = 0):\n",
    "    model.train()\n",
    "    text = preprocess(word)\n",
    "    actual_len = 1\n",
    "    if len(text) < min_len:\n",
    "        text += ['<pad>'] * (min_len - len(text))\n",
    "    indexed = [Text.vocab.stoi[t] for t in text]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    input_indices = torch.tensor(indexed, device=device)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "    text_length = torch.tensor([actual_len], device=device)\n",
    "    # input_indices dim: [sequence_length]\n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = F.softmax(model(input_indices, text_length)[0]).cpu()\n",
    "\n",
    "\n",
    "    vis_word.append(pred.detach().numpy().squeeze(0))\n",
    "    colorlist.append({0:'#00ff00', 1: '#00ffff', 2:'#000000' }[pred.argmax(dim=1).item()])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kMTrDK7sz9kt"
   },
   "source": [
    "for i in Text.vocab.itos:\n",
    "    interpret_word(lstm_model, i)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ndkX6219z9kt"
   },
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_top_ted_tsne = tsne.fit_transform(vis_word)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:55:28.003009Z",
     "start_time": "2021-04-05T15:55:27.883014Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Yd79T06dz9kt"
   },
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"vector T-SNE for most polarized words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
    "                                    x2=words_top_ted_tsne[:,1],\n",
    "                                    names=Text.vocab.itos,\n",
    "                                    color=colorlist))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, fill_color=\"color\")\n",
    "\n",
    "word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                       text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                       source=source, text_align='center',render_mode='canvas')\n",
    "# p.add_layout(word_labels)\n",
    "\n",
    "show(p)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T15:55:20.282440Z",
     "start_time": "2021-04-05T15:55:20.162442Z"
    },
    "id": "wWbpD19Dz9ku"
   },
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"vector T-SNE for most polarized words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
    "                                    x2=words_top_ted_tsne[:,1],\n",
    "                                    names=Text.vocab.itos,\n",
    "                                    color=colorlist))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, fill_color=\"color\")\n",
    "\n",
    "word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                       text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                       source=source, text_align='center',render_mode='canvas')\n",
    "p.add_layout(word_labels)\n",
    "\n",
    "show(p)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}