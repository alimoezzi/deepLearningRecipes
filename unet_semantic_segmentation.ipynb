{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "unet_semantic_segmentation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CvZPm89CEg71"
      },
      "source": [
        "# Semantic Segmentation using U-NET model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYHXyMeAEnuj",
        "outputId": "52481a73-4563-4950-8644-a56adde6f4f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install -q kaggle albumentations torch pytorch_lightning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 39.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40 kB 39.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 51 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 61 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 71 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 81 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 92 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 102 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 112 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 122 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 133 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 143 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 153 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 163 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 174 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 184 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 194 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 204 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 215 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 225 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 235 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 245 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 256 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 266 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 276 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 286 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 296 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 307 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 317 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 327 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 337 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 348 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 358 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 368 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 378 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 389 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 399 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 409 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 419 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 430 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 440 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 450 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 460 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 471 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 481 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 491 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 501 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 512 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 522 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 532 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 542 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 552 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 563 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 573 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 583 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 593 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 604 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 614 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 624 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 634 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 645 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 655 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 665 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 675 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 686 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 696 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 706 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 716 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 727 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 737 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 747 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 757 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 768 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 778 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 788 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 798 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 808 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 813 kB 30.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 631 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 56.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 26.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 52.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 58.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 58.5 MB/s \n",
            "\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WomrObEQE7Qt"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKd3mvQYFAOQ",
        "outputId": "4392b502-36c4-4142-d7d3-c53f03353711",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e84759d7-75ea-4c52-96c2-e3a3b1536714\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e84759d7-75ea-4c52-96c2-e3a3b1536714\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 63 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0geAwrCFiWI",
        "outputId": "2a766e93-fe4d-40de-b1ee-ff92e53d4c47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir -p .pytorch/carvanasemseg/\n",
        "!kaggle competitions download -c carvana-image-masking-challenge -f train.zip -p .pytorch/carvanasemseg/\n",
        "!kaggle competitions download -c carvana-image-masking-challenge -f train_masks.zip -p .pytorch/carvanasemseg/\n",
        "!kaggle competitions download -c carvana-image-masking-challenge -f train_masks.csv.zip -p .pytorch/carvanasemseg/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train.zip to .pytorch/carvanasemseg\n",
            "100% 403M/405M [00:02<00:00, 154MB/s]\n",
            "100% 405M/405M [00:02<00:00, 148MB/s]\n",
            "Downloading train_masks.zip to .pytorch/carvanasemseg\n",
            " 96% 28.0M/29.1M [00:00<00:00, 116MB/s] \n",
            "100% 29.1M/29.1M [00:00<00:00, 129MB/s]\n",
            "Downloading train_masks.csv.zip to .pytorch/carvanasemseg\n",
            " 59% 9.00M/15.3M [00:00<00:00, 69.7MB/s]\n",
            "100% 15.3M/15.3M [00:00<00:00, 74.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0T_tmokFpMC"
      },
      "source": [
        "!python -m zipfile -e .pytorch/carvanasemseg/train.zip  .pytorch/carvanasemseg/\n",
        "!python -m zipfile -e .pytorch/carvanasemseg/train_masks.zip  .pytorch/carvanasemseg/\n",
        "!python -m zipfile -e .pytorch/carvanasemseg/train_masks.csv.zip .pytorch/carvanasemseg/"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "fKNfNzegEg74"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nTEszw5fEg74"
      },
      "source": [
        "# visualization library\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "# data storing library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# torch libraries\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader, Dataset, sampler\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "# architecture and data split library\n",
        "from sklearn.model_selection import train_test_split\n",
        "# augmentation library\n",
        "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import os\n",
        "import pdb\n",
        "import time\n",
        "import warnings\n",
        "import random\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import concurrent.futures\n",
        "\n",
        "# warning print supression\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "HrDjttydEg77"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "V7leU1ViEg78"
      },
      "source": [
        "### Fixing seed value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wiVIYSepEg79"
      },
      "source": [
        "def setSeed(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "setSeed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d2JMQVCdEg7-"
      },
      "source": [
        "# !mkdir -p '.pytorch/carvanasemseg/'\n",
        "# !mkdir -p '.pytorch/carvanasemseg/train_masks_png/'\n",
        "# !mkdir -p '.pytorch/carvanasemseg/train-128/'\n",
        "# !mkdir -p '.pytorch/carvanasemseg/train_masks-128/'\n",
        "\n",
        "def convert_img(fn):\n",
        "    PIL.Image.open(f'.pytorch/carvanasemseg/train_masks/{fn}').save(\n",
        "        f'.pytorch/carvanasemseg/train_masks_png/{fn[:-4]}.png')  #opening and saving image\n",
        "\n",
        "\n",
        "fns = os.listdir('.pytorch/carvanasemseg/train_masks')\n",
        "with concurrent.futures.ThreadPoolExecutor(8) as e:\n",
        "    e.map(convert_img, fns)\n",
        "\n",
        "\n",
        "def resize_mask(fn):\n",
        "    PIL.Image.open('.pytorch/carvanasemseg/train_masks_png/' + fn).resize((128, 128)).save(\n",
        "        f'.pytorch/carvanasemseg/train_masks-128/{fn}')\n",
        "\n",
        "\n",
        "fns = os.listdir('.pytorch/carvanasemseg/train_masks_png/')\n",
        "with concurrent.futures.ThreadPoolExecutor(8) as e:\n",
        "    e.map(resize_mask, fns)\n",
        "\n",
        "\n",
        "# we convert the high resolution input image to 128*128\n",
        "def resize_img(fn):\n",
        "    PIL.Image.open('.pytorch/carvanasemseg/train/' + fn).resize((128, 128)).save(\n",
        "        f'.pytorch/carvanasemseg/train-128/{fn}')\n",
        "\n",
        "\n",
        "fns = os.listdir('.pytorch/carvanasemseg/train/')\n",
        "with concurrent.futures.ThreadPoolExecutor(8) as e:\n",
        "    e.map(resize_img, fns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qiADyjQJEg8B"
      },
      "source": [
        "df = pd.read_csv('.pytorch/carvanasemseg/train_masks.csv')\n",
        "# location of original and mask image\n",
        "img_fol = '.pytorch/carvanasemseg/train-128/'\n",
        "mask_fol = '.pytorch/carvanasemseg/train_masks-128/'\n",
        "# imagenet mean/std will be used as the resnet backbone is trained on imagenet stats\n",
        "mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x39GxWtKEg8C",
        "outputId": "ec1889dd-cfd0-45bf-e22e-172b3f1a5837"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   img                                           rle_mask\n",
              "0  00087a6bd4dc_01.jpg  879386 40 881253 141 883140 205 885009 17 8850...\n",
              "1  00087a6bd4dc_02.jpg  873779 4 875695 7 877612 9 879528 12 881267 15...\n",
              "2  00087a6bd4dc_03.jpg  864300 9 866217 13 868134 15 870051 16 871969 ...\n",
              "3  00087a6bd4dc_04.jpg  879735 20 881650 26 883315 92 883564 30 885208...\n",
              "4  00087a6bd4dc_05.jpg  883365 74 883638 28 885262 119 885550 34 88716..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>rle_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00087a6bd4dc_01.jpg</td>\n",
              "      <td>879386 40 881253 141 883140 205 885009 17 8850...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00087a6bd4dc_02.jpg</td>\n",
              "      <td>873779 4 875695 7 877612 9 879528 12 881267 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00087a6bd4dc_03.jpg</td>\n",
              "      <td>864300 9 866217 13 868134 15 870051 16 871969 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00087a6bd4dc_04.jpg</td>\n",
              "      <td>879735 20 881650 26 883315 92 883564 30 885208...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00087a6bd4dc_05.jpg</td>\n",
              "      <td>883365 74 883638 28 885262 119 885550 34 88716...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OPiUfEqjEg8I"
      },
      "source": [
        "### Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TtTwa0tsEg8J"
      },
      "source": [
        "# input-->\"phase\",mean,std\n",
        "# output-->list\n",
        "def get_transform(phase, mean, std):\n",
        "    list_trans = []\n",
        "    if phase == 'train':  # only flip during training\n",
        "        list_trans.extend([HorizontalFlip(p=0.5)])\n",
        "    list_trans.extend(\n",
        "        [Normalize(mean=mean, std=std, p=1), ToTensorV2()])  #normalizing the data & then converting to tensors\n",
        "    list_trans = Compose(list_trans)\n",
        "    return list_trans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "KovUGZCqEg8K"
      },
      "source": [
        "### Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hfRub4A2Eg8K"
      },
      "source": [
        "\n",
        "class CarDataset(Dataset):\n",
        "    def __init__(self, df, img_fol, mask_fol, mean, std, phase):\n",
        "        self.fname = df['img'].values.tolist()\n",
        "        self.img_fol = img_fol\n",
        "        self.mask_fol = mask_fol\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.phase = phase\n",
        "        self.trasnform = get_transform(phase, mean, std)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.fname[idx]\n",
        "        img_name_path = os.path.join(self.img_fol, name)\n",
        "        mask_name_path = os.path.join(self.mask_fol, name.replace('.jpg', '_mask.png'))\n",
        "        img = cv2.imread(img_name_path)\n",
        "        mask = cv2.imread(mask_name_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = np.where(mask==255, 1, 0)\n",
        "        augmentation = self.trasnform(image=img, mask=mask)\n",
        "        img_aug = augmentation['image'].type(torch.float32)  #[3,128,128] type:Tensor\n",
        "        mask_aug = augmentation['mask'].type(torch.int64)    #[1,128,128] type:Tensor\n",
        "        return img_aug, mask_aug\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JTygRVz-Eg8L"
      },
      "source": [
        "def CarDataloader(df, img_fol, mask_fol, mean, std, batch_size, num_workers):\n",
        "    df_train, df_valid = train_test_split(df, test_size=0.2, random_state=69)\n",
        "    traindataset = CarDataset(df_train, img_fol, mask_fol, mean, std, 'train')\n",
        "    traindataloader = DataLoader(traindataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
        "    valdataset = CarDataset(df_valid, img_fol, mask_fol, mean, std, 'test')\n",
        "    valdataloader = DataLoader(valdataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    return traindataloader, valdataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LEI809qxEg8N"
      },
      "source": [
        "NUM_WORKER = 0\n",
        "BATCH_SIZE = 1\n",
        "train_dl, val_dl = CarDataloader(df, img_fol, mask_fol, mean, std, batch_size=BATCH_SIZE, num_workers=NUM_WORKER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r4Ic3DQAEg8N",
        "outputId": "96c9106a-a80b-4ee9-f2f6-e375bb852ddb"
      },
      "source": [
        "xb, yb = next(iter(train_dl))\n",
        "xb.shape, yb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 128, 128]), torch.Size([1, 128, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "YC_SIqQ4Eg8O"
      },
      "source": [
        "## UNET Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4KNXym05Eg8O"
      },
      "source": [
        "class UNET(pl.LightningModule):\n",
        "    def __init__(self, in_channels, out_channels, lr=0.01):\n",
        "        super().__init__()\n",
        "        self.learning_rate = lr\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n",
        "        self.conv2 = self.contract_block(32, 64, 3, 1)\n",
        "        self.conv3 = self.contract_block(64, 128, 3, 1)\n",
        "\n",
        "        self.upconv3 = self.expand_block(128, 64, 3, 1)\n",
        "        self.upconv2 = self.expand_block(64 * 2, 32, 3, 1)\n",
        "        self.upconv1 = self.expand_block(32 * 2, out_channels, 3, 1)\n",
        "\n",
        "    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n",
        "        contract = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        return contract\n",
        "\n",
        "    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n",
        "        expand = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "        )\n",
        "        return expand\n",
        "\n",
        "    def forward(self, x):\n",
        "        # down-sampling\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(conv1)\n",
        "        conv3 = self.conv3(conv2)\n",
        "\n",
        "        # upsampling\n",
        "        upconv3 = self.upconv3(conv3)\n",
        "        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n",
        "        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n",
        "\n",
        "        return upconv1\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return CarDataloader(df, img_fol, mask_fol, mean, std, batch_size=BATCH_SIZE, num_workers=NUM_WORKER)[0]\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return CarDataloader(df, img_fol, mask_fol, mean, std, batch_size=BATCH_SIZE, num_workers=NUM_WORKER)[1]\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return CarDataloader(df, img_fol, mask_fol, mean, std, batch_size=BATCH_SIZE, num_workers=NUM_WORKER)[1]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "\n",
        "        outputs = self(x)\n",
        "        loss = F.cross_entropy(outputs, y)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        outputs = self(x)\n",
        "        loss = self.loss(outputs, y)\n",
        "        acc = (outputs.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        # Calling self.log will surface up scalars for you in TensorBoard\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # Here we just reuse the validation_step for testing\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mot4Dz-QEg8U"
      },
      "source": [
        "unet = UNET(3, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "x0RAEiZfEg8V"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BXSyh--jEg8V",
        "outputId": "f05672c0-a2e3-44e9-bc6c-0e70f6cfc8cf"
      },
      "source": [
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "trainer = pl.Trainer(\n",
        "    gpus=AVAIL_GPUS,\n",
        "    max_epochs=50,\n",
        "    progress_bar_refresh_rate=20,\n",
        "    # accumulate_grad_batches=0,\n",
        "    gradient_clip_val=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "S9Gl-No7Eg8X",
        "outputId": "f86393d9-9f1c-4cfa-b258-efaab41d4763",
        "colab": {
          "referenced_widgets": [
            "87e2d95c8d6a48d092d85c14c57af85e",
            "498ef2c96d7e43b8a76e4bba008c9d89",
            "ff445e0046554e48aabd0df466bacd92"
          ]
        }
      },
      "source": [
        "trainer.fit(unet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name    | Type             | Params\n",
            "---------------------------------------------\n",
            "0 | loss    | CrossEntropyLoss | 0     \n",
            "1 | conv1   | Sequential       | 55.1 K\n",
            "2 | conv2   | Sequential       | 55.7 K\n",
            "3 | conv3   | Sequential       | 221 K \n",
            "4 | upconv3 | Sequential       | 147 K \n",
            "5 | upconv2 | Sequential       | 55.5 K\n",
            "6 | upconv1 | Sequential       | 1.2 K \n",
            "---------------------------------------------\n",
            "537 K     Trainable params\n",
            "0         Non-trainable params\n",
            "537 K     Total params\n",
            "2.149     Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87e2d95c8d6a48d092d85c14c57af85e"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "498ef2c96d7e43b8a76e4bba008c9d89"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff445e0046554e48aabd0df466bacd92"
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}