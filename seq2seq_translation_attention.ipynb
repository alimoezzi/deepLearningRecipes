{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "seq2seq_translation_attention.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "T0CUqI56C9V9"
      },
      "source": [
        "# Machine Learning using seq2seq architecture with attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ql1UG4OeC9WC",
        "outputId": "8ee104a0-e1a9-479e-f309-6324744b6f5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "! curl https://download.pytorch.org/tutorial/data.zip --create-dirs -o '.pytorch/engfr/data.zip'\n",
        "! python -m zipfile -e '.pytorch/engfr/data.zip' '.pytorch/engfr/'\n",
        "! mv .pytorch/engfr/data/* .pytorch/engfr/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 2814k  100 2814k    0     0  30.5M      0 --:--:-- --:--:-- --:--:-- 30.5M\n",
            "mv: cannot move '.pytorch/engfr/data/names' to '.pytorch/engfr/names': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uSepgT4-C9WF"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kHQ1J4C2C9WG"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3fkgqt4HC9WH"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AIvhIi-XC9WJ"
      },
      "source": [
        "## read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1kG0nTPVC9WJ"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('.pytorch/engfr/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aH40yeGHC9WL"
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kD2AZfrCC9WM",
        "outputId": "0796a0d6-8081-4ee0-a716-5c8c05ffd962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 13033 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 5143\n",
            "eng 3371\n",
            "['il est insatisfait du resultat .', 'he is unsatisfied with the result .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KBvyEySxC9WP"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IjA1nldMC9WR"
      },
      "source": [
        "## Model implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vmC9rJVlC9WR"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dTKMGkYqC9WS"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "drVlOWscC9WU"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MBcmzJfQC9WW"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gWQkYckJC9WY"
      },
      "source": [
        "### Attention Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bxvqRU2mC9WY"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zHKFw8dfC9Wa"
      },
      "source": [
        "## Train & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "e54BOPbBC9Wb"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "P7a3P4vFC9Wb"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E0sXVrktC9Wd"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def checkpoint_and_save(model):\n",
        "    print('saving')\n",
        "    torch.save(model[0].state_dict(),'checkpoint/eng_fr_encoder.t7')\n",
        "    torch.save(model[1].state_dict(),'checkpoint/eng_fr_decoder.t7')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6QEhz3k6C9We"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zBHIIbjNC9Wf"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    best_loss = 999999\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "        \n",
        "        if loss < best_loss:\n",
        "          best_loss = loss\n",
        "          best_epoch = iter\n",
        "          checkpoint_and_save((encoder, decoder))\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "x4qiFndeC9Wh"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DJxICkLcC9Wi"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "L4GdWINOC9Wj"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        targets.append(pair[1])\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        outputs.append(output_sentence)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "    print(len(outputs), len(targets))\n",
        "    print(outputs)\n",
        "    print(targets)\n",
        "    print(f'Bleu Score: {bleu_score(outputs, targets)}')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AtN567UcC9Wk"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "psPBco1bC9Wk",
        "outputId": "71a3fed0-57a7-4f08-ba5e-ecda74a25502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "import os\n",
        "if os.path.isdir('checkpoint') and os.path.isfile('./checkpoint/eng_fr_decoder.t7'):\n",
        "    encoder1.load_state_dict(torch.load('./checkpoint/eng_fr_encoder.t7', map_location=torch.device(device)))\n",
        "    attn_decoder1.load_state_dict(torch.load('./checkpoint/eng_fr_decoder.t7', map_location=torch.device(device)))\n",
        "if not os.path.isdir('checkpoint'):\n",
        "  os.mkdir('checkpoint')\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "1m 19s (- 18m 38s) (5000 6%) 2.9665\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "2m 38s (- 17m 10s) (10000 13%) 2.4691\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "3m 57s (- 15m 50s) (15000 20%) 2.1527\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "5m 16s (- 14m 31s) (20000 26%) 1.9391\n",
            "saving\n",
            "6m 35s (- 13m 11s) (25000 33%) 1.7722\n",
            "saving\n",
            "7m 54s (- 11m 52s) (30000 40%) 1.6312\n",
            "saving\n",
            "saving\n",
            "9m 13s (- 10m 32s) (35000 46%) 1.5491\n",
            "saving\n",
            "saving\n",
            "saving\n",
            "10m 32s (- 9m 13s) (40000 53%) 1.3974\n",
            "saving\n",
            "11m 50s (- 7m 53s) (45000 60%) 1.3251\n",
            "saving\n",
            "saving\n",
            "13m 9s (- 6m 34s) (50000 66%) 1.2529\n",
            "14m 27s (- 5m 15s) (55000 73%) 1.1766\n",
            "15m 46s (- 3m 56s) (60000 80%) 1.1346\n",
            "17m 5s (- 2m 37s) (65000 86%) 1.1146\n",
            "saving\n",
            "18m 23s (- 1m 18s) (70000 93%) 1.0428\n",
            "saving\n",
            "saving\n",
            "19m 42s (- 0m 0s) (75000 100%) 0.9784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "55bePQWrC9Wm",
        "outputId": "bfb5368c-4e09-4e84-d04d-4e3f8d006f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> vous n etes plus en prise avec la realite .\n",
            "= you re out of touch with reality .\n",
            "< you re out of touch with reality . <EOS>\n",
            "\n",
            "> j entends beaucoup ca ces derniers temps .\n",
            "= i m hearing that a lot lately .\n",
            "< i m just trying to a a . . . <EOS>\n",
            "\n",
            "> ils jalousent notre succes .\n",
            "= they are jealous of our success .\n",
            "< they are jealous of our success . <EOS>\n",
            "\n",
            "> vous etes plus grands que moi .\n",
            "= you are taller than me .\n",
            "< you are taller than me . <EOS>\n",
            "\n",
            "> ils sont chanceux d etre en vie .\n",
            "= they re lucky to be alive .\n",
            "< they re lucky to be alive . <EOS>\n",
            "\n",
            "> je fais usage de cette tasse .\n",
            "= i m using that cup .\n",
            "< i am using that cup . <EOS>\n",
            "\n",
            "> elle est inquiete a propos de la sante de son fils .\n",
            "= she is concerned about her son s health .\n",
            "< she is concerned about her son s health . <EOS>\n",
            "\n",
            "> je ne suis pas votre ennemie .\n",
            "= i m not your enemy .\n",
            "< i am not your enemy . <EOS>\n",
            "\n",
            "> je suis en train de jouer avec mes amies .\n",
            "= i m playing with my friends .\n",
            "< i m playing with my friends . <EOS>\n",
            "\n",
            "> elle est vieille .\n",
            "= she is old .\n",
            "< she is old . <EOS>\n",
            "\n",
            "10 10\n",
            "['you re out of touch with reality . <EOS>', 'i m just trying to a a . . . <EOS>', 'they are jealous of our success . <EOS>', 'you are taller than me . <EOS>', 'they re lucky to be alive . <EOS>', 'i am using that cup . <EOS>', 'she is concerned about her son s health . <EOS>', 'i am not your enemy . <EOS>', 'i m playing with my friends . <EOS>', 'she is old . <EOS>']\n",
            "['you re out of touch with reality .', 'i m hearing that a lot lately .', 'they are jealous of our success .', 'you are taller than me .', 'they re lucky to be alive .', 'i m using that cup .', 'she is concerned about her son s health .', 'i m not your enemy .', 'i m playing with my friends .', 'she is old .']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-752866089bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-119630193720>\u001b[0m in \u001b[0;36mevaluateRandomly\u001b[0;34m(encoder, decoder, n)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Bleu Score: {bleu_score(outputs, targets)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
          ]
        }
      ]
    }
  ]
}