{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deep dream with VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torchvision import models, transforms\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "from io import BytesIO\n",
    "import torchvision\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.transforms import transforms\n",
    "from torchsummary import summary\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize = (200,50))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,928\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
      "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
      "             ReLU-12            [-1, 256, 8, 8]               0\n",
      "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-14            [-1, 256, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-16            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-17            [-1, 256, 4, 4]               0\n",
      "           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n",
      "             ReLU-19            [-1, 512, 4, 4]               0\n",
      "           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-21            [-1, 512, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-23            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-24            [-1, 512, 2, 2]               0\n",
      "           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-26            [-1, 512, 2, 2]               0\n",
      "           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-30            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-31            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.84\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 532.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = vgg16(pretrained=True)\n",
    "model.load_state_dict(torch.load('.pytorch/VGG16/vgg16-397923af.pth'))\n",
    "summary(model, input_size=(3,32,32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(device(type='cpu'), VGG(\n   (features): Sequential(\n     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (1): ReLU(inplace=True)\n     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (3): ReLU(inplace=True)\n     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n     (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (6): ReLU(inplace=True)\n     (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (8): ReLU(inplace=True)\n     (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n     (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (11): ReLU(inplace=True)\n     (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (13): ReLU(inplace=True)\n     (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (15): ReLU(inplace=True)\n     (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n     (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (18): ReLU(inplace=True)\n     (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (20): ReLU(inplace=True)\n     (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (22): ReLU(inplace=True)\n     (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n     (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (25): ReLU(inplace=True)\n     (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (27): ReLU(inplace=True)\n     (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n     (29): ReLU(inplace=True)\n     (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n   )\n   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n   (classifier): Sequential(\n     (0): Linear(in_features=25088, out_features=4096, bias=True)\n     (1): ReLU(inplace=True)\n     (2): Dropout(p=0.5, inplace=False)\n     (3): Linear(in_features=4096, out_features=4096, bias=True)\n     (4): ReLU(inplace=True)\n     (5): Dropout(p=0.5, inplace=False)\n     (6): Linear(in_features=4096, out_features=1000, bias=True)\n   )\n ))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device, model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "def showtensor(a):\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n",
    "    inp = a[0, :, :, :]\n",
    "    inp = inp.transpose(1, 2, 0)\n",
    "    inp = std * inp + mean\n",
    "    inp *= 255\n",
    "    showarray(inp)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "def plot_images(im, titles=None):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "\n",
    "    for i in range(len(im)):\n",
    "        plt.subplot(10 / 5 + 1, 5, i + 1)\n",
    "        plt.axis('off')\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "        plt.imshow(im[i])\n",
    "\n",
    "    plt.pause(0.001)\n",
    "\n",
    "normalise = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "normalise_resize = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def init_image(size=(400, 400, 3)):\n",
    "    img = PIL.Image.fromarray(np.uint8(np.full(size, 150)))\n",
    "    img = PIL.Image.fromarray(np.uint8(np.random.uniform(150, 180, size)))\n",
    "    img_tensor = normalise(img).unsqueeze(0)\n",
    "    img_np = img_tensor.numpy()\n",
    "    return img, img_tensor, img_np\n",
    "\n",
    "def load_image(path, resize=False, size=None):\n",
    "    img = PIL.Image.open(path)\n",
    "\n",
    "    if size is not None:\n",
    "        img.thumbnail(size, PIL.Image.ANTIALIAS)\n",
    "\n",
    "    if resize:\n",
    "        img_tensor = normalise_resize(img).unsqueeze(0)\n",
    "    else:\n",
    "        img_tensor = normalise(img).unsqueeze(0)\n",
    "    img_np = img_tensor.numpy()\n",
    "    return img, img_tensor, img_np\n",
    "\n",
    "def tensor_to_img(t):\n",
    "    a = t.numpy()\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n",
    "    inp = a[0, :, :, :]\n",
    "    inp = inp.transpose(1, 2, 0)\n",
    "    inp = std * inp + mean\n",
    "    inp *= 255\n",
    "    inp = np.uint8(np.clip(inp, 0, 255))\n",
    "    return PIL.Image.fromarray(inp)\n",
    "\n",
    "def image_to_variable(image, requires_grad=False):\n",
    "    image = Variable(image.to(device), requires_grad=requires_grad)\n",
    "    return image\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37464bit831585bc47394299a89c79954db4f3b1",
   "language": "python",
   "display_name": "Python 3.7.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}