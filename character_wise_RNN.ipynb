{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# character-wise RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Overview](https://github.com/udacity/deep-learning/raw/78c91a5607ecfdc29b762e45c082d7ca5047c8a1/intro-to-rnns/assets/charseq.jpeg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'35. ABDOMEN AND PELVIC SONOGRAPHY:\\nLiver is normal in size and with normal parenchymal echogenicity '"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('.pytorch/trialReport/trial.txt') as r:\n",
    "    reports = r.read()\n",
    "reports[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabs:\n",
      " ['\\n', ' ', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'أ', '—']\n",
      "int to vocab:\n",
      " {0: '\\n', 1: ' ', 2: '&', 3: \"'\", 4: '(', 5: ')', 6: '*', 7: ',', 8: '-', 9: '.', 10: '/', 11: '0', 12: '1', 13: '2', 14: '3', 15: '4', 16: '5', 17: '6', 18: '7', 19: '8', 20: '9', 21: ':', 22: ';', 23: '=', 24: 'A', 25: 'B', 26: 'C', 27: 'D', 28: 'E', 29: 'F', 30: 'G', 31: 'H', 32: 'I', 33: 'K', 34: 'L', 35: 'M', 36: 'N', 37: 'O', 38: 'P', 39: 'Q', 40: 'R', 41: 'S', 42: 'T', 43: 'U', 44: 'V', 45: 'W', 46: 'Y', 47: '\\\\', 48: 'a', 49: 'b', 50: 'c', 51: 'd', 52: 'e', 53: 'f', 54: 'g', 55: 'h', 56: 'i', 57: 'j', 58: 'k', 59: 'l', 60: 'm', 61: 'n', 62: 'o', 63: 'p', 64: 'q', 65: 'r', 66: 's', 67: 't', 68: 'u', 69: 'v', 70: 'w', 71: 'x', 72: 'y', 73: 'z', 74: 'أ', 75: '—'}\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(reports))\n",
    "print('vocabs:\\n', vocab)\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "print('int to vocab:\\n', int_to_vocab)\n",
    "vocab_to_int = {v: i for i,v in int_to_vocab.items()}\n",
    "encoded = np.array([vocab_to_int[v] for v in reports], dtype=np.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([14, 16,  9,  1, 24, 25, 27, 37, 35, 28, 36,  1, 24, 36, 27,  1, 38,\n       28, 34, 44, 32, 26,  1, 41, 37, 36, 37, 30, 40, 24, 38, 31, 46, 21,\n        0, 34, 56, 69, 52, 65,  1, 56, 66,  1, 61, 62, 65, 60, 48, 59,  1,\n       56, 61,  1, 66, 56, 73, 52,  1, 48, 61, 51,  1, 70, 56, 67, 55,  1,\n       61, 62, 65, 60, 48, 59,  1, 63, 48, 65, 52, 61, 50, 55, 72, 60, 48,\n       59,  1, 52, 50, 55, 62, 54, 52, 61, 56, 50, 56, 67, 72,  1])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot Encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "\n",
    "    return np.eye(n_labels,n_labels,  dtype=np.float32)[arr]\n",
    "# check that the function works as expected\n",
    "test_seq = np.array([[3, 5, 1]])\n",
    "one_hot = one_hot_encode(test_seq, 8)\n",
    "\n",
    "print(one_hot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batching"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "                M steps ( seq length )\n",
    "               xxx                 xxx\n",
    "               x                     x\n",
    "               x                     x                                Starting sequence:\n",
    "               x                     x                                [1 2 3 4 5 6 7 8 9 10 11 12]\n",
    "               x                     x\n",
    "N batch size   x                     x                                Batch size = 2\n",
    "(No. of steps) x                     x                                [1 2 3 4 5 6]\n",
    "               x                     x                                [7 8 9 10 11 12]\n",
    "               x                     x\n",
    "               x                     x                                Seq length = 3\n",
    "               x                     x\n",
    "               x                     x                                  ┌─────┐\n",
    "               x                     x                                [ │1 2 3│ 4 5 6]\n",
    "               x                     x                                [ │7 8 9│ 10 11 12]\n",
    "               x                     x                                  └─────┘\n",
    "               xxx                 xxx\n",
    "\n",
    "            xxxxxxxxxxxxxx   xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "                         xxxxx\n",
    "                          xx\n",
    "\n",
    "                          k= No. of batches = total chars/ N.M"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def create_batches(arr, batch_size, seq_length):\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "    arr = arr[:n_batches*batch_size_total]\n",
    "    arr = arr.reshape((batch_size,-1))\n",
    "\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[14 16  9  1 24 25 27 37 35 28]\n",
      " [48 65 67  1 62 53  1 26 25 27]\n",
      " [50 48 69 56 67 72  9  0 18 14]\n",
      " [61 62 65 60 48 59  1 56 61  1]\n",
      " [54 61  1 62 53  1 66 63 48 50]\n",
      " [67 55 52  1 48 49 51 62 60 56]\n",
      " [65 72  1 49 59 48 51 51 52 65]\n",
      " [56 50  1 50 48 69 56 67 72  9]]\n",
      "\n",
      "y:\n",
      " [[16  9  1 24 25 27 37 35 28 36]\n",
      " [65 67  1 62 53  1 26 25 27  1]\n",
      " [48 69 56 67 72  9  0 18 14  9]\n",
      " [62 65 60 48 59  1 56 61  1 66]\n",
      " [61  1 62 53  1 66 63 48 50 52]\n",
      " [55 52  1 48 49 51 62 60 56 61]\n",
      " [72  1 49 59 48 51 51 52 65  1]\n",
      " [50  1 50 48 69 56 67 72  9  0]]\n"
     ]
    }
   ],
   "source": [
    "batches = create_batches(encoded, 8, 50)\n",
    "x, y= next(batches)\n",
    "print('x:\\n', x[:10, :10])\n",
    "print('\\ny:\\n', y[:10, :10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class textgenRNN(nn.Module):\n",
    "    def __init__(self,n_output, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.lstm = nn.LSTM(n_output, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hid = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out, hid\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if (device != 'cpu'):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "\n",
    "        return hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textgenRNN(\n",
      "  (lstm): LSTM(76, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=76, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "n_hidden=512\n",
    "n_layers=2\n",
    "model = textgenRNN(len(vocab), n_hidden=n_hidden, n_layers=n_layers)\n",
    "model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}