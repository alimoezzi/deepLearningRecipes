{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# character-wise RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Overview](https://github.com/udacity/deep-learning/raw/78c91a5607ecfdc29b762e45c082d7ca5047c8a1/intro-to-rnns/assets/charseq.jpeg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'35. ABDOMEN AND PELVIC SONOGRAPHY:\\nLiver is normal in size and with normal parenchymal echogenicity '"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('.pytorch/trialReport/trial.txt') as r:\n",
    "    reports = r.read()\n",
    "reports[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabs:\n",
      " ['\\n', ' ', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'أ', '—']\n",
      "int to vocab:\n",
      " {0: '\\n', 1: ' ', 2: '&', 3: \"'\", 4: '(', 5: ')', 6: '*', 7: ',', 8: '-', 9: '.', 10: '/', 11: '0', 12: '1', 13: '2', 14: '3', 15: '4', 16: '5', 17: '6', 18: '7', 19: '8', 20: '9', 21: ':', 22: ';', 23: '=', 24: 'A', 25: 'B', 26: 'C', 27: 'D', 28: 'E', 29: 'F', 30: 'G', 31: 'H', 32: 'I', 33: 'K', 34: 'L', 35: 'M', 36: 'N', 37: 'O', 38: 'P', 39: 'Q', 40: 'R', 41: 'S', 42: 'T', 43: 'U', 44: 'V', 45: 'W', 46: 'Y', 47: '\\\\', 48: 'a', 49: 'b', 50: 'c', 51: 'd', 52: 'e', 53: 'f', 54: 'g', 55: 'h', 56: 'i', 57: 'j', 58: 'k', 59: 'l', 60: 'm', 61: 'n', 62: 'o', 63: 'p', 64: 'q', 65: 'r', 66: 's', 67: 't', 68: 'u', 69: 'v', 70: 'w', 71: 'x', 72: 'y', 73: 'z', 74: 'أ', 75: '—'}\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(reports))\n",
    "print('vocabs:\\n', vocab)\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "print('int to vocab:\\n', int_to_vocab)\n",
    "vocab_to_int = {v: i for i,v in int_to_vocab.items()}\n",
    "encoded = np.array([vocab_to_int[v] for v in reports], dtype=np.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([14, 16,  9,  1, 24, 25, 27, 37, 35, 28, 36,  1, 24, 36, 27,  1, 38,\n       28, 34, 44, 32, 26,  1, 41, 37, 36, 37, 30, 40, 24, 38, 31, 46, 21,\n        0, 34, 56, 69, 52, 65,  1, 56, 66,  1, 61, 62, 65, 60, 48, 59,  1,\n       56, 61,  1, 66, 56, 73, 52,  1, 48, 61, 51,  1, 70, 56, 67, 55,  1,\n       61, 62, 65, 60, 48, 59,  1, 63, 48, 65, 52, 61, 50, 55, 72, 60, 48,\n       59,  1, 52, 50, 55, 62, 54, 52, 61, 56, 50, 56, 67, 72,  1])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot Encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "\n",
    "    return np.eye(n_labels,n_labels,  dtype=np.float32)[arr]\n",
    "# check that the function works as expected\n",
    "test_seq = np.array([[3, 5, 1]])\n",
    "one_hot = one_hot_encode(test_seq, 8)\n",
    "\n",
    "print(one_hot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batching"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "                M steps ( seq length )\n",
    "               xxx                 xxx\n",
    "               x                     x\n",
    "               x                     x                                Starting sequence:\n",
    "               x                     x                                [1 2 3 4 5 6 7 8 9 10 11 12]\n",
    "               x                     x\n",
    "N batch size   x                     x                                Batch size = 2\n",
    "(No. of steps) x                     x                                [1 2 3 4 5 6]\n",
    "               x                     x                                [7 8 9 10 11 12]\n",
    "               x                     x\n",
    "               x                     x                                Seq length = 3\n",
    "               x                     x\n",
    "               x                     x                                  ┌─────┐\n",
    "               x                     x                                [ │1 2 3│ 4 5 6]\n",
    "               x                     x                                [ │7 8 9│ 10 11 12]\n",
    "               x                     x                                  └─────┘\n",
    "               xxx                 xxx\n",
    "\n",
    "            xxxxxxxxxxxxxx   xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "                         xxxxx\n",
    "                          xx\n",
    "\n",
    "                          k= No. of batches = total chars/ N.M"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def create_batches(arr, batch_size, seq_length):\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "    arr = arr[:n_batches*batch_size_total]\n",
    "    arr = arr.reshape((batch_size,-1))\n",
    "\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[14 16  9  1 24 25 27 37 35 28]\n",
      " [48 65 67  1 62 53  1 26 25 27]\n",
      " [50 48 69 56 67 72  9  0 18 14]\n",
      " [61 62 65 60 48 59  1 56 61  1]\n",
      " [54 61  1 62 53  1 66 63 48 50]\n",
      " [67 55 52  1 48 49 51 62 60 56]\n",
      " [65 72  1 49 59 48 51 51 52 65]\n",
      " [56 50  1 50 48 69 56 67 72  9]]\n",
      "\n",
      "y:\n",
      " [[16  9  1 24 25 27 37 35 28 36]\n",
      " [65 67  1 62 53  1 26 25 27  1]\n",
      " [48 69 56 67 72  9  0 18 14  9]\n",
      " [62 65 60 48 59  1 56 61  1 66]\n",
      " [61  1 62 53  1 66 63 48 50 52]\n",
      " [55 52  1 48 49 51 62 60 56 61]\n",
      " [72  1 49 59 48 51 51 52 65  1]\n",
      " [50  1 50 48 69 56 67 72  9  0]]\n"
     ]
    }
   ],
   "source": [
    "batches = create_batches(encoded, 8, 50)\n",
    "x, y= next(batches)\n",
    "print('x:\\n', x[:10, :10])\n",
    "print('\\ny:\\n', y[:10, :10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class textgenRNN(nn.Module):\n",
    "    def __init__(self,n_output, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.lstm = nn.LSTM(n_output, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hid = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out, hid\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "\n",
    "        return hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textgenRNN(\n",
      "  (lstm): LSTM(76, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=76, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "n_hidden=512\n",
    "n_layers=2\n",
    "model = textgenRNN(len(vocab), n_hidden=n_hidden, n_layers=n_layers)\n",
    "model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isdir('checkpoint') and os.path.isfile('./checkpoint/trialckpt.t7'):\n",
    "    model.load_state_dict(torch.load('./checkpoint/trialckpt.t7', map_location=torch.device(device)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "epochs=10\n",
    "batch_size=10\n",
    "seq_length=50\n",
    "lr=0.001\n",
    "clip=5\n",
    "test_portion=0.1\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create training and validation data\n",
    "data, test_data = train_test_split(encoded, test_size=test_portion)\n",
    "\n",
    "# change model mode to train\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "textgenRNN(\n  (lstm): LSTM(76, 512, num_layers=2, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc): Linear(in_features=512, out_features=76, bias=True)\n)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 10... Loss: 3.2636... Val Loss: 3.2152\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 20... Loss: 3.1667... Val Loss: 3.1808\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 30... Loss: 3.2193... Val Loss: 3.1779\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 40... Loss: 3.2427... Val Loss: 3.1700\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 50... Loss: 3.1305... Val Loss: 3.1694\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 60... Loss: 3.1558... Val Loss: 3.1664\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 70... Loss: 3.1496... Val Loss: 3.1694\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 80... Loss: 3.1554... Val Loss: 3.1678\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 90... Loss: 3.2365... Val Loss: 3.1673\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 100... Loss: 3.2155... Val Loss: 3.1686\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 110... Loss: 3.0264... Val Loss: 3.1661\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 120... Loss: 3.1628... Val Loss: 3.1654\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 130... Loss: 3.1676... Val Loss: 3.1672\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 140... Loss: 3.2486... Val Loss: 3.1693\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 150... Loss: 3.1895... Val Loss: 3.1676\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 160... Loss: 3.2219... Val Loss: 3.1679\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 170... Loss: 3.1546... Val Loss: 3.1674\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 180... Loss: 3.1441... Val Loss: 3.1693\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 190... Loss: 3.3101... Val Loss: 3.1657\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 200... Loss: 3.2051... Val Loss: 3.1694\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 210... Loss: 3.2104... Val Loss: 3.1639\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 220... Loss: 3.1529... Val Loss: 3.1650\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 230... Loss: 3.0883... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 240... Loss: 3.1303... Val Loss: 3.1633\n",
      "==> Saving model ...\n",
      "Epoch: 1/10... Step: 250... Loss: 3.0860... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 260... Loss: 3.2120... Val Loss: 3.1658\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 270... Loss: 3.1911... Val Loss: 3.1675\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 280... Loss: 3.2241... Val Loss: 3.1674\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 290... Loss: 3.1333... Val Loss: 3.1677\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 300... Loss: 3.2189... Val Loss: 3.1635\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 310... Loss: 3.0812... Val Loss: 3.1621\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 320... Loss: 3.1938... Val Loss: 3.1649\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 330... Loss: 3.1983... Val Loss: 3.1658\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 340... Loss: 3.1659... Val Loss: 3.1644\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 350... Loss: 3.1892... Val Loss: 3.1646\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 360... Loss: 3.2442... Val Loss: 3.1641\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 370... Loss: 3.1517... Val Loss: 3.1634\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 380... Loss: 3.1728... Val Loss: 3.1640\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 390... Loss: 3.1502... Val Loss: 3.1655\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 400... Loss: 3.1553... Val Loss: 3.1658\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 410... Loss: 3.1347... Val Loss: 3.1656\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 420... Loss: 3.3186... Val Loss: 3.1648\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 430... Loss: 3.1689... Val Loss: 3.1644\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 440... Loss: 3.1240... Val Loss: 3.1656\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 450... Loss: 3.1590... Val Loss: 3.1670\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 460... Loss: 3.1575... Val Loss: 3.1623\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 470... Loss: 3.1736... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 480... Loss: 3.0886... Val Loss: 3.1633\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 490... Loss: 3.2596... Val Loss: 3.1630\n",
      "==> Saving model ...\n",
      "Epoch: 2/10... Step: 500... Loss: 3.1090... Val Loss: 3.1621\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 510... Loss: 3.2231... Val Loss: 3.1637\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 520... Loss: 3.1207... Val Loss: 3.1654\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 530... Loss: 3.2675... Val Loss: 3.1659\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 540... Loss: 3.0984... Val Loss: 3.1659\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 550... Loss: 3.1822... Val Loss: 3.1634\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 560... Loss: 3.1831... Val Loss: 3.1616\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 570... Loss: 3.1898... Val Loss: 3.1635\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 580... Loss: 3.2565... Val Loss: 3.1648\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 590... Loss: 3.1874... Val Loss: 3.1630\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 600... Loss: 3.1847... Val Loss: 3.1635\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 610... Loss: 3.2403... Val Loss: 3.1630\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 620... Loss: 3.1766... Val Loss: 3.1626\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 630... Loss: 3.1505... Val Loss: 3.1630\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 640... Loss: 3.0541... Val Loss: 3.1644\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 650... Loss: 3.1296... Val Loss: 3.1646\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 660... Loss: 3.1749... Val Loss: 3.1640\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 670... Loss: 3.1698... Val Loss: 3.1646\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 680... Loss: 3.1304... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 690... Loss: 3.1488... Val Loss: 3.1645\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 700... Loss: 3.1975... Val Loss: 3.1651\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 710... Loss: 3.1899... Val Loss: 3.1626\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 720... Loss: 3.1765... Val Loss: 3.1627\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 730... Loss: 3.1613... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 740... Loss: 3.1113... Val Loss: 3.1624\n",
      "==> Saving model ...\n",
      "Epoch: 3/10... Step: 750... Loss: 3.1132... Val Loss: 3.1616\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 760... Loss: 3.1602... Val Loss: 3.1627\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 770... Loss: 3.1595... Val Loss: 3.1642\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 780... Loss: 3.1205... Val Loss: 3.1647\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 790... Loss: 3.2314... Val Loss: 3.1654\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 800... Loss: 3.2325... Val Loss: 3.1634\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 810... Loss: 3.1306... Val Loss: 3.1611\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 820... Loss: 3.1367... Val Loss: 3.1626\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 830... Loss: 3.1874... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 840... Loss: 3.2176... Val Loss: 3.1628\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 850... Loss: 3.1059... Val Loss: 3.1625\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 860... Loss: 3.1220... Val Loss: 3.1622\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 870... Loss: 3.2097... Val Loss: 3.1625\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 880... Loss: 3.1890... Val Loss: 3.1628\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 890... Loss: 3.2032... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 900... Loss: 3.1789... Val Loss: 3.1637\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 910... Loss: 3.0994... Val Loss: 3.1633\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 920... Loss: 3.1223... Val Loss: 3.1639\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 930... Loss: 3.1979... Val Loss: 3.1634\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 940... Loss: 3.1917... Val Loss: 3.1642\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 950... Loss: 3.1963... Val Loss: 3.1642\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 960... Loss: 3.2072... Val Loss: 3.1629\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 970... Loss: 3.1251... Val Loss: 3.1620\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 980... Loss: 3.2123... Val Loss: 3.1637\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 990... Loss: 3.0895... Val Loss: 3.1621\n",
      "==> Saving model ...\n",
      "Epoch: 4/10... Step: 1000... Loss: 3.1304... Val Loss: 3.1615\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1010... Loss: 3.2144... Val Loss: 3.1624\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1020... Loss: 3.1544... Val Loss: 3.1639\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1030... Loss: 3.1469... Val Loss: 3.1638\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1040... Loss: 3.1749... Val Loss: 3.1650\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1050... Loss: 3.1900... Val Loss: 3.1634\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1060... Loss: 3.2181... Val Loss: 3.1610\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1070... Loss: 3.0342... Val Loss: 3.1622\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1080... Loss: 3.1734... Val Loss: 3.1630\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1090... Loss: 3.1684... Val Loss: 3.1628\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1100... Loss: 3.2145... Val Loss: 3.1626\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1110... Loss: 3.1427... Val Loss: 3.1621\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1120... Loss: 3.1838... Val Loss: 3.1623\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1130... Loss: 3.1942... Val Loss: 3.1626\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1140... Loss: 3.0958... Val Loss: 3.1633\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1150... Loss: 3.1925... Val Loss: 3.1634\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1160... Loss: 3.1963... Val Loss: 3.1632\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1170... Loss: 3.1282... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1180... Loss: 3.1591... Val Loss: 3.1637\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1190... Loss: 3.1808... Val Loss: 3.1640\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1200... Loss: 3.1463... Val Loss: 3.1641\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1210... Loss: 3.1335... Val Loss: 3.1628\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1220... Loss: 3.1425... Val Loss: 3.1617\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1230... Loss: 3.1957... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1240... Loss: 3.2170... Val Loss: 3.1615\n",
      "==> Saving model ...\n",
      "Epoch: 5/10... Step: 1250... Loss: 3.2822... Val Loss: 3.1614\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1260... Loss: 3.2791... Val Loss: 3.1618\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1270... Loss: 3.1151... Val Loss: 3.1635\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1280... Loss: 3.1738... Val Loss: 3.1634\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1290... Loss: 3.2218... Val Loss: 3.1646\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1300... Loss: 3.1804... Val Loss: 3.1638\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1310... Loss: 3.2108... Val Loss: 3.1610\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1320... Loss: 3.1822... Val Loss: 3.1617\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1330... Loss: 3.0857... Val Loss: 3.1623\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1340... Loss: 3.1265... Val Loss: 3.1629\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1350... Loss: 3.2256... Val Loss: 3.1622\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1360... Loss: 3.1949... Val Loss: 3.1621\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1370... Loss: 3.1922... Val Loss: 3.1622\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1380... Loss: 3.2198... Val Loss: 3.1625\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1390... Loss: 3.2213... Val Loss: 3.1629\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1400... Loss: 3.1849... Val Loss: 3.1631\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1410... Loss: 3.2482... Val Loss: 3.1632\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1420... Loss: 3.0944... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1430... Loss: 3.2103... Val Loss: 3.1638\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1440... Loss: 3.0910... Val Loss: 3.1637\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1450... Loss: 3.1221... Val Loss: 3.1636\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1460... Loss: 3.1480... Val Loss: 3.1629\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1470... Loss: 3.1653... Val Loss: 3.1615\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1480... Loss: 3.1392... Val Loss: 3.1632\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1490... Loss: 3.1730... Val Loss: 3.1616\n",
      "==> Saving model ...\n",
      "Epoch: 6/10... Step: 1500... Loss: 3.1591... Val Loss: 3.1614\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1510... Loss: 3.2602... Val Loss: 3.1612\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1520... Loss: 3.1647... Val Loss: 3.1628\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1530... Loss: 3.1924... Val Loss: 3.1632\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1540... Loss: 3.1250... Val Loss: 3.1646\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1550... Loss: 3.2230... Val Loss: 3.1639\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1560... Loss: 3.1751... Val Loss: 3.1613\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1570... Loss: 3.1850... Val Loss: 3.1614\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1580... Loss: 3.2039... Val Loss: 3.1620\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1590... Loss: 3.1469... Val Loss: 3.1631\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1600... Loss: 3.2655... Val Loss: 3.1623\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1610... Loss: 3.1030... Val Loss: 3.1619\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1620... Loss: 3.1486... Val Loss: 3.1622\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1630... Loss: 3.1665... Val Loss: 3.1624\n",
      "==> Saving model ...\n",
      "Epoch: 7/10... Step: 1640... Loss: 3.2251... Val Loss: 3.1624\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-29-13faffb9970b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[1;31m# get the output from the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m         \u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[1;31m# calculate the loss and perform backprop\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-25-f672af245d30>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, hidden)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m         \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    580\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mbatch_sizes\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    581\u001B[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001B[1;32m--> 582\u001B[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001B[0m\u001B[0;32m    583\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    584\u001B[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "n_vocab = len(vocab)\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "\n",
    "    for x, y in create_batches(data, batch_size, seq_length):\n",
    "        counter += 1\n",
    "\n",
    "        # One-hot encode our data and make them Torch tensors\n",
    "        x = one_hot_encode(x, n_vocab)\n",
    "        inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optim.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % 10 == 0:\n",
    "            # Get validation loss\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for x, y in create_batches(test_data, batch_size, seq_length):\n",
    "                # One-hot encode our data and make them Torch tensors\n",
    "                x = one_hot_encode(x, n_vocab)\n",
    "                x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs, targets = x, y\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                output, val_h = model(inputs, val_h)\n",
    "                val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            print('==> Saving model ...')\n",
    "\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(model.state_dict(), './checkpoint/trialckpt.t7')\n",
    "\n",
    "            model.train() # reset to train mode after iterationg through validation data\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting next character"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(model, inputs, h=None, top_k= None):\n",
    "    x = np.array([[vocab_to_int[inputs]]])\n",
    "    x = one_hot_encode(x, len(vocab))\n",
    "    inp = torch.from_numpy(x).to(device)\n",
    "\n",
    "    # get access to hidden state\n",
    "    h = tuple([i.data for i in h])\n",
    "    # pass inputs and hidden state to model\n",
    "    out, h = model(inp, h)\n",
    "\n",
    "    # get prob of the char\n",
    "    p = F.softmax(out, dim=1).data\n",
    "    p = p.to('cpu')\n",
    "\n",
    "    if top_k is None:\n",
    "        top_ch = np.arange(len(vocab))\n",
    "    else:\n",
    "        p, top_ch = p.topk(top_k)\n",
    "        top_ch = top_ch.numpy().squeeze()\n",
    "\n",
    "    p = p.numpy.squeeze()\n",
    "    v = np.random.choice(top_ch, p=p/p.sum())\n",
    "\n",
    "    return int_to_vocab[v], h\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample(model, size, prime='The', top_k=None):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval() # eval mode\n",
    "\n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = model.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(model, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "\n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)\n",
    "print(sample(model, 1000, prime='Liver', top_k=5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}