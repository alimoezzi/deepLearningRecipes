{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine translation Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/html": "\n    <div class=\"bk-root\">\n        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n        <span id=\"1001\">Loading BokehJS ...</span>\n    </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import imblearn\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.utils import tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torchtext.datasets import IWSLT2017\n",
    "from torchtext.legacy import data\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "# from torchtext import data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from numpy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "# ! pip install captum bokeh spacy emot parameter-sherpa\n",
    "import sherpa\n",
    "import captum\n",
    "import random\n",
    "import spacy\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, IntegratedGradients, LayerConductance\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "import emot\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download de\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz already exists.\n",
      "INFO:root:Validating hash aca701032b1c4411afc4d9fa367796ba matches hash of C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz\n",
      "INFO:root:Opening tar file C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/._texts.html already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts.html already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._.eval already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/.eval already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._.info already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/.info already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._DeEnItNlRo-DeEnItNlRo.tgz already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo.tgz already extracted.\n",
      "INFO:root:Finished extracting tar file C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz.\n",
      "INFO:root:Opening tar file .pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo.tgz.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-en.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-it.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-nl.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-ro.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-de.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-it.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-nl.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-ro.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-de.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-en.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-nl.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-ro.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-de.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-en.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-it.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-ro.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-de.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-en.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-it.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-nl.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-en.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-it.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-nl.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-ro.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-de.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-it.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-nl.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-ro.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-de.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-en.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-nl.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-ro.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-de.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-en.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-it.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-ro.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-de.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-en.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-it.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-nl.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/README already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-en.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-it.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-nl.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-ro.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-de.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-it.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-nl.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-ro.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-de.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-en.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-nl.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-ro.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-de.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-en.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-it.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-ro.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-de.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-en.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-it.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-nl.ro already extracted.\n",
      "INFO:root:Finished extracting tar file .pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo.tgz.\n",
      "INFO:root:File C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz already exists.\n",
      "INFO:root:Validating hash aca701032b1c4411afc4d9fa367796ba matches hash of C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz\n",
      "INFO:root:Opening tar file C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/._texts.html already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts.html already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._.eval already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/.eval already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._.info already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/.info already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._DeEnItNlRo-DeEnItNlRo.tgz already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo.tgz already extracted.\n",
      "INFO:root:Finished extracting tar file C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz.\n",
      "INFO:root:Opening tar file .pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo.tgz.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-en.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-it.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-nl.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-ro.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-de.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-it.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-nl.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-ro.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-de.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-en.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-nl.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-ro.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-de.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-en.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-it.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-ro.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-de.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-en.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-it.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-nl.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-en.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-it.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-nl.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-ro.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-de.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-it.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-nl.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-ro.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-de.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-en.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-nl.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-ro.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-de.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-en.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-it.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-ro.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-de.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-en.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-it.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-nl.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/README already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-en.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-it.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-nl.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-ro.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-de.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-it.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-nl.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-ro.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-de.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-en.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-nl.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-ro.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-de.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-en.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-it.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-ro.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-de.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-en.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-it.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-nl.ro already extracted.\n",
      "INFO:root:Finished extracting tar file .pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo.tgz.\n",
      "INFO:root:File C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz already exists.\n",
      "INFO:root:Validating hash aca701032b1c4411afc4d9fa367796ba matches hash of C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz\n",
      "INFO:root:Opening tar file C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/._texts.html already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts.html already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._.eval already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/.eval already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._.info already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/.info already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/._DeEnItNlRo-DeEnItNlRo.tgz already extracted.\n",
      "INFO:root:C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo.tgz already extracted.\n",
      "INFO:root:Finished extracting tar file C:\\Users\\User\\YandexDisk\\myAI\\myNLP\\deepLearningRecipes\\.pytorch\\.data\\2017-01-trnmted.tgz.\n",
      "INFO:root:Opening tar file .pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo.tgz.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-en.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-it.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-nl.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-ro.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-de.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-it.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-nl.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-ro.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.en-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-de.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-en.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-nl.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-ro.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.it-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-de.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-en.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-it.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-ro.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.nl-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-de.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-en.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-it.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.ro-nl.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-en.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-it.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-nl.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-ro.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-de.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-it.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-nl.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-ro.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.en-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-de.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-en.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-nl.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-ro.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.it-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-de.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-en.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-it.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-ro.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.nl-ro.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-de.de.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-de.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-en.en.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-en.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-it.it.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-it.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-nl.nl.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.ro-nl.ro.xml already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/README already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-en.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-it.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-nl.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-ro.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.de-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-de.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-it.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-nl.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-ro.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.en-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-de.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-en.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-nl.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-ro.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.it-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-de.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-en.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-it.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-ro.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.nl-ro.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-de.de already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-de.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-en.en already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-en.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-it.it already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-it.ro already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-nl.nl already extracted.\n",
      "INFO:root:.pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo/train.tags.ro-nl.ro already extracted.\n",
      "INFO:root:Finished extracting tar file .pytorch/.data/2017-01-trnmted\\texts/DeEnItNlRo/DeEnItNlRo\\DeEnItNlRo-DeEnItNlRo.tgz.\n"
     ]
    }
   ],
   "source": [
    "spacy_german = spacy.load(\"de\")\n",
    "spacy_english = spacy.load(\"en\")\n",
    "\n",
    "def tokenize_german(text):\n",
    "    return [token.text.lower() for token in spacy_german.tokenizer(text)]\n",
    "\n",
    "def tokenize_english(text):\n",
    "    return [token.text.lower() for token in spacy_english.tokenizer(text)]\n",
    "\n",
    "train_iter, valid_iter, test_iter, = IWSLT2017(root='.pytorch/.data/', language_pair=('en','de'))\n",
    "train_data = list(train_iter)\n",
    "valid_data = list(valid_iter)\n",
    "test_data = list(test_iter)\n",
    "en_counter = Counter()\n",
    "de_counter = Counter()\n",
    "\n",
    "for (en, de) in train_data:\n",
    "    en_counter.update(tokenize_english(en))\n",
    "    de_counter.update(tokenize_german(de))\n",
    "\n",
    "german = Vocab(de_counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n",
    "english = Vocab(en_counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabs 15927\n",
      "Unique tokens in source (en) vocabs 13190\n"
     ]
    }
   ],
   "source": [
    "print(f'Unique tokens in source (de) vocabs {len(german)}')\n",
    "print(f'Unique tokens in source (en) vocabs {len(english)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of the text_transform: [1, 78, 18, 54, 225, 2]\n"
     ]
    }
   ],
   "source": [
    "english_transform = lambda x: [english['<BOS>']] + [english[token] for token in tokenize_english(x)] + [english['<EOS>']]\n",
    "german_transform = lambda x: [german['<BOS>']] + [german[token] for token in tokenize_german(x)] + [german['<EOS>']]\n",
    "print(\"output of the text_transform:\", english_transform(\"here is an example\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating Batch iterator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[   1,    1,    1,  ...,    1,    1,    1],\n         [  15,   14,    7,  ...,   13,   16,   23],\n         [  18,    7, 3794,  ..., 3303,  184, 4037],\n         ...,\n         [   3,    3,    3,  ...,    3,    3,    3],\n         [   3,    3,    3,  ...,    3,    3,    3],\n         [   3,    3,    3,  ...,    3,    3,    3]]),\n tensor([[    1,     1,     1,  ...,     1,     1,     1],\n         [11412,     0,   712,  ...,     0,   272,     0],\n         [    0,   609,     0,  ...,     0,     0,     0],\n         ...,\n         [    3,     3,     3,  ...,     3,     3,     3],\n         [    3,     3,     3,  ...,     3,     3,     3],\n         [    3,     3,     3,  ...,     3,     3,     3]]))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "BATCH_SIZE=32\n",
    "def collate_batch(batch):\n",
    "    de_list, en_list = [], []\n",
    "    for (_en, _de) in batch:\n",
    "        en_list.append(torch.tensor(english_transform(_en)))\n",
    "        de_list.append(torch.tensor(english_transform(_de)))\n",
    "    return pad_sequence(en_list, padding_value=3.0), pad_sequence(de_list, padding_value=3.0)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderLSTM(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(13190, 300)\n",
      "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.input_size = input_size # size of input one-hot vector\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size # output size of embedding NN\n",
    "        self.hidden_size = hidden_size # Dimension of NN's inside lstm cell\n",
    "        num_layers = num_layers # no of stacked lstm\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size) # [input size, embedding dims]\n",
    "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout=p) # [embedding dims, hidden size, num layers]\n",
    "\n",
    "    def forward(self, x):\n",
    "        embd = self.dropout(self.embedding(x)) # x: [Sequence_length, batch_size] emd: [Sequence_length , batch_size , embedding dims]\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embd) # output: [Sequence_length , batch_size , hidden_size] (hs, cs): [num_layers, batch_size size, hidden_size]\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "input_size_encoder = len(english)\n",
    "encoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "encoder_dropout = float(0.5)\n",
    "\n",
    "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
    "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
    "print(encoder_lstm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderLSTM(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(15927, 300)\n",
      "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "  (fc1): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=15927, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "\n",
    "        self.input_size = input_size # size of one-hot input vector\n",
    "        self.embedding_size = embedding_size # output size embedding layer\n",
    "        self.hidden_size = hidden_size # dim of NN inside lstm memory\n",
    "        self.num_layers = num_layers # no of stacked lstm\n",
    "        self.output_size = output_size # size of one-hot vector (target language)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size) # [input size, embedding dims]\n",
    "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout=p) # [embedding dims, hidden size, num layers]\n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden_size, self.hidden_size*2)\n",
    "        self.fc2 = nn.Linear(self.hidden_size*2, self.output_size)\n",
    "\n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        x = x.unsqueeze(0) # [1, batch_size]\n",
    "\n",
    "        embd = self.dropout(self.embedding(x)) # [1, batch_size, embedding dims]\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embd, (hidden_state, cell_state)) # [num_layers, batch_size size, hidden_size]\n",
    "        fc = self.fc1(outputs)\n",
    "        pred = self.fc2(self.dropout(fc))\n",
    "\n",
    "        pred = pred.squeeze(0)\n",
    "        return  pred, hidden_state, cell_state\n",
    "\n",
    "\n",
    "input_size_decoder = len(german)\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "decoder_dropout = float(0.5)\n",
    "output_size = len(german)\n",
    "\n",
    "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
    "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
    "print(decoder_lstm)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.Encoder_LSTM = Encoder_LSTM\n",
    "        self.Decoder_LSTM = Decoder_LSTM\n",
    "\n",
    "    def forward(self, source, target, tfr=0.5):\n",
    "        batch_size = source.shape[1] # [ seq length, No. of seq]\n",
    "\n",
    "        target_len = target.shape[0] # [ seq length, No. of seq]\n",
    "        target_vocab_size = len(german)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source)\n",
    "\n",
    "        x = target[0] # trigger <BOS>\n",
    "\n",
    "        for i in range(1, target_len):\n",
    "            output, hidden_state_decoder, cell_state_decoder = self.Decoder_LSTM(x, hidden_state_encoder, cell_state_encoder)\n",
    "            outputs[i] = output\n",
    "            pred = output.argmax(1)\n",
    "            x = target[i] if np.random.rand() < tfr else pred\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "writer = SummaryWriter(f\".pytorch/runs/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = english.stoi[\"<PAD>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (Encoder_LSTM): EncoderLSTM(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(13190, 300)\n",
      "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "  )\n",
      "  (Decoder_LSTM): DecoderLSTM(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(15927, 300)\n",
      "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "    (fc1): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    (fc2): Linear(in_features=2048, out_features=15927, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def translate_sentenece(model, sentence, english, german, device, max_length=50):\n",
    "    sentence_tensor = torch.LongTensor(english_transform(sentence)).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hid, cell = model.Encoder_LSTM(sentence_tensor)\n",
    "\n",
    "    outputs = [german.stoi[\"<BOS>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hid, cell = model.Decoder_LSTM(previous_word, hid, cell)\n",
    "            pred = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(pred)\n",
    "\n",
    "        if output.argmax(1).item() == german.stoi['<EOS>']:\n",
    "            break\n",
    "    res = [german.itos[i] for i in outputs]\n",
    "    return res[1:]\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for e in data:\n",
    "        src = e[0]\n",
    "        trg = e[1]\n",
    "        pred = translate_sentenece(model, src, english, german, device)\n",
    "        pred = pred[:-1]\n",
    "        targets.append([trg])\n",
    "        outputs.append(pred)\n",
    "    return  bleu_score(outputs, targets)\n",
    "\n",
    "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
    "    print('saving')\n",
    "    print()\n",
    "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
    "    torch.save(state, '/content/checkpoint-NMT')\n",
    "    torch.save(model.state_dict(),'checkpoint/eng_ger')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 / 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-30-e3ff00255fc8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# calculate the loss for every epoch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m         \u001B[1;31m# clip the gradient if it exceeds 1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    244\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 245\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    145\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 147\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epoch_loss = 0.0\n",
    "num_epochs = 100\n",
    "best_loss = 999999\n",
    "best_epoch = -1\n",
    "sentence1 = \"output of the text_transform\"\n",
    "ts1s = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch - {epoch+1} / {num_epochs}')\n",
    "    model.eval()\n",
    "    ts1 = translate_sentenece(model, sentence1, english, german, device)\n",
    "    print(f\"Translated example sentence 1: \\n {ts1}\")\n",
    "    ts1s.append(ts1)\n",
    "\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        input = batch[0].to(device)\n",
    "        target = batch[0].to(device)\n",
    "\n",
    "        # pass the input to the model\n",
    "        output = model(input, target)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad() # clear out the accumulating grads\n",
    "\n",
    "        loss = criterion(output, target) # calculate the loss for every epoch\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the gradient if it exceeds 1\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        epoch_loss += loss.item()\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss)\n",
    "\n",
    "        if (epoch - best_epoch) >= 10:\n",
    "            print('Model not converging in the last 10 epochs')\n",
    "            break\n",
    "    print(f'Epoch loss - {loss.item()}')\n",
    "    print()\n",
    "\n",
    "print(epoch_loss / len(train_dataloader))\n",
    "\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f'Bleu score {.2:score*100}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}